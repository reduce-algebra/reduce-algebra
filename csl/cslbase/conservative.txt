                     Conservative Garbage Collection
                     ===============================


Version as if April 2022.

Previous attempts here perhaps suffered from the "Second System Effect", so
this version is trimmed down somewhat.

Memory is grabbed from the OS in "segments" where the first such is of
size (probably) 64MB and each subsequent one is twice the size of its
predecessor until memory start to get full. This is intended to lead to
modest calculations completing within a sane footprint while large ones
being able to get all the memory they might need. There can be up to 16
segments, so binary search can identify which segment (if any) a potential
pointer falls within in 4 or 5 comparisons. Segments are all aligned at
8MB boundaries.

Each segment is considered to be made up of a sequence of 8MB pages. There
are two sorts of page - CONS pages and VEC pages. Their internal structures
are different. Pages that are in use at all will be in one of the following
states: EMPTY, CONSPIN, VECPIN, CONSFULL, VECFULL. One CONS and one VEC
page will be "current" which will mean that some information that will
eventually be stored within it is instead in variables for immediate use.

There are three initial processes that I wish to describe first:

(1) Allocation of a new CONS cell.
This will involve a CURRENT/CONS page so interacts with the structure there.
I note that a GC earlier on may have left "pinned" CONS cells within the
page, and I must allocate around them. The page will have two pointers, free
and limit. In most cases the code executed for allocation will be
    LispObject r = free;
    free += 2*sizeof(LispObject);
    if (free <= limit) return r;
and I hope that that sequence can get compiled in-line where it is used.
A part empty CONS page will contain live data up as far as fringe. From there
to limit has undefined content. Limit is either the end of the page or is
a previously pinned item. A bitmap identified all previously pinned data,
so when it is necessary to skip same that can be consulted and the fringe
pointer moved to the location just beyond all pinned data in a block. The
cell there contains a pointer defining space up to either the next pinned
item or the end of the page. Obviously before any allocation has happened
in a CONS page its first non-pinned location will contain such a value.
So when a new CONS page is opened the steps taken need to be along the
lines of:
    fringe = <start of data region>;
// The next line assumes that the page will not be 100% full of pinned
// cells. That pathological case needs to be covered by avoiding any
// attempt to re-use such a page.
    while (location_is_pinned(fringe)) fringe += 2*sizeof(LispObject);
    limit = fringe + *fringe;
When a CONS page is to be made full all that happens is that its fringe
pointer is stored in its header.

In previous plans I had considered multi-thread activity. If I revive that
plan then each thread will have its own 8MB CURRENT pages and the
variable fringe and limit become thread-local. That would mean that use of
atomic operations and the like would only happen when pages become full.

Note here that a CONS for the purposes of this section can be any Lisp
item that fits in exactly two cells. So Lisp vectors with just one element,
double precision floats, bignums needing only one word of data and strings
short enough to fit would all qualify. The expectation is that this is the
sort of data with greatest turn-over.

(2) Allocation of a new vector.
This happens in the current VEC Page and is for all larger objects. It is
going to turn out that handling pinned vectors is much messier than pinned
CONS cells because the ambiguous reference may point at an arbitrary
location within the vector, but it will end up important to identify
the start address of the pinned item.
A VEC page is considered as made up of 16KB chunks. As well as a map that
tags pinned items within the page there is one that provides information
about each chunk. The main need for this is that chunks may be marked as
"continuations" when items of size over 16KB need to be allocated.
Within a VEC page if there is any item that is pinned that means that the
whole chunk (or chunk plus continuation chunks) containing it must be
avoided during allocation.

I hope that the best way of setting up an understanding of allocation will
be to describe the memory state arrived at. First I will use the word Chunk
with a capital letter to mean either a single chunk or an initial chunk
followed by one or more continuations. In an 8MB page there can only be 512
chunks so part of the page header will include a map showing for each chunk
whether it is initial, and if it is a continuation whether it is successor
1, 2, 3 etc. Well at some stage I will make the continuation number saturate
but from the continuation number I can skip back from a location in the
middle of an extended Chunk and find its start.
The page laout will begin with zero or more Chunks each of which is full,
in that all space within will be accounted for. This is acheived by placing
padder objects after all genuine data. Withing a Chunk that contains pinned
material there will be padder objects before, between and after the pinned
vectors.

There will then be a Chunk that during allocation has fringe and limit
pointers (much as in the CONS pages). Chunks beyond this active one are
either ones containing pinned data or the memory in them has unspecified
content. The map that contains chunk information needs to be set up for
all those chunks so that it is possible to discriminate between these two
cases.

(3) Investigation of an ambiguous value that may be a pointer to valid data.
This has to be done at the start of GC, and must end with both a catalogue
of all valid items referred to and with a quick way to test if a particular
item is referenced this way. I will use the term "pinned" for items so
referenced. A complication is that a value from the C++ stack may point not
at the head word of a multi-word item but anywhere within it.
Given a potential pointer the first thing to do is to use binary search to
identify which segment (if any) it points within. Obviously if it does not
point within any segment it can be ignored. Next the page involved can be
extracted by a simple mask operation. But within the last-allocated segment
it may be that only the first few pages have been brought into use, so a
check against the address of the section of that segment that is in use
is needed.

Now for any pointer the page that it lies within is known. The header of that
page can be checked to see if it is a CONS or VEC page. At the time (in the
GC) when I do this I will want to have arranged that the two "current" pages
have been tagged or padded at the end so there is no awkwardness about the
unused space at their end.

For a CONS page a pointer is valid if it lies below the fringe or if it
was pinned by a previous GC. Within such pages the granularity of pinning
will be 2*sizeof(LispObject) and two bitmaps are required, one recording
items pinned by earlier GCs and the other for ones that will now be pinned.
This process is performed at the start of a GC and at that stage there will
be a new half-space ready for use. When an item becomed pinned it needs to
be added to a chain that is built in the new half-space with the page
header holding the head of that chain. That setup arranges that later parts
of the GC can visit and process all pinned items. This list will be built
such that items in it are not sorted. Towards the end of GC it will be
necessary to sort the list and use it to construct the sequence of padder
headers that are required when allocation in the recycled page start.

Naturally for VEC pages things are messier! Again there will be two bitmaps,
one noting previously pinned items and the other ones pinned this time round.
The first step will be that the Chunk that a pointer lies within is identified
and if this is one containing previously pinned data the pin-now mark is
set on the call referred to. If the Chunk is one beyond where data has been
placed the reference is ignored. Otherwise the pin-now mark is set. In both
cases of a preumptive pin the Chunk is marked as containing data that
may be pinned and a chain of such Chunks is make in the new half-space.
Pages containing such chunks are chained together.

Now all pinned items in CONS pages have been ser, but in VEC pages the
pin bit may be set on a word within the vector. But because CONS pages
have been dealt with it will be possible to scan all the lists of
pinned items and clear pin bits on the cells making up those lists. Well
if any did get pinned then they will themselves appear in a pinned item
list, so I may wish to take any such pinned cell and edit reference to it
out from the list concerned. This is perhaps a bit over-fussy?

After all the ambiguous pointers have been processed this far a second
pass is needed to arrange that pinning information refers to the heads
of objects and never to padders. The chain of pages is traversed, and for
each page the chain of Chunks inspected. The chunk has to be parsed to
identify each object in it, and pin bits for every address within the
object checked. If any are then the pin map is adjusted so there is a tag
against the first word of the object but no others. Working on the bitmap
as a sequence of 64-bit words rather than as 1-bit entities makes the
core of this much less painful that it could be!

The step here is the one that I feel has the worst cost in the process of
identifying pinned items. A Chunk that (may) contain pinned items can either
be one containing previously pinned stuff or it can be one with fresh data
in it. In either case it has to be parsed, starting from its start, so that
all the objects within it are delimited. If a (new) pinned mark is present
on any word within an object then that pinned mark is moved to tag the first
word of the object, and the object is placed on a chain of pinned items in
the new heap. Well if the object identified that way is a padder then it
should not be pinned. Done simply this process involved around 2K probes
in each 16KB chunk, and I do not really like that. However it is done in
the context of a GC that is about to visit and copy all the live data in the
entire active world, and its cost will be trifling measured against that!
At the end of this sweep all items that are to be viewed as pinned during
this gc will have a mark associated with their first word. for a VEC page
the bitmap must have a bit for every 8-byte word, and so the bitmaps will
be twice the size that they are in CONS pages. So on a CONS page each of the
two bitmaps will use 64KB and in a VEC page each will fill 128KB.

So let me comment a bit more on the map for chunks. There can be 512 chunks
in a page (well ssomewhat fewer because space is used at the start of the
page for header information including bitmaps). Well if I recognise that the
128+128KB of pinning bitmaps are not filled with chunks I only need 496,
ie 16 fewer. Anyway I will use one byte for information about each chunk.
One bit if that indicates whether the chunk contains live or pinned data.
That leaves 7 bits. A value 0 indicated a starter chunk. Values 1,2,...
indicate continuation chunks up to some point N (maybe N=127 but it could be
lower if I find a need for more codes for some other purpose). Beyond that
each successor chunk is marked with N. If an ambiguous pointer refers to a
chunk marked with non-zero value m then the pointer is reduced by 16384*m
for processing - the effect is that vectors of length up to around 16KB*N
find their header chunk instently and ones beyond that step back in
units on N chunks. I.e. reasonably rapidly.

After these initial scans that identify currently-pinned items I need to
evacuate all such. I can have set up a chain of pages that contain pinned
data and within such pages there are the headers of chains that identify the
pinned material. Well I do not want those chains to be able to lead to
material being preserved, for instance if an ambiguous pointer referred to
a location within such a chain. So I will build the chains using values
tagged as immediate data and hence not looking like further pointers. This
does not lose much since almost by the nature of things when an ambiguous
pointer refers to anything it will not have reliable tag bits, so I need to
identify the object type by inspection anyway.
 
At the end of a GC the "current" maps of pinned items will need to be copied
to the "previous" location, and the current ones may properly be cleared
ahead of the next GC. But also I will need to create the patterns that
make freed pages ready for re-use. For any page the first check will be
whether it contains any pinned data. If not it can be recorded as a FREE 
page and claimed later for either CONS or VEC use.
If a CONS page contains some pinned items then it refers to a chain of them.
This chain must be sorted so that padder headers can be written in between
the pinned items. To do that I think I will find a FREE page and copy the
list of pinned items into it as a contiguous block that can them be sorted
as a vector. Well actually the page for use does not need to be totally free,
provided there is an available clear space in it large enough for the number
of pinned items to be processed. I think that the unavailability of such a
page would be extraordinary pathological so any recovery from that can be
"odd" and I may take the view that it represents a fatal exhaustion of
memory. However at the start of a GC it may be useful to claim one FREE
page (if one is available) for this purpose and not copy live data into
it during GC, use it this way at GC end but then leave it available for
allocation during the subsequent run.
A VEC page will have the same sort of treatment save that the chunk structure
within it will need to be sorted out. Note that one of the pinning bitmaps
is now available for use as workspace to help arrange that and is large
enough to be used to hold a vector of pinned chunks if that helps!

Now I have covered the "special" aspects of the scheme, I will just fill in
the main steps on the GC

(1) Convert CONSCURRENT and VECCURRENT into CONSFULL and VECFULL by
    transferring the global fringe pointers into their headers and as
    necessary  padder headers.
(2) Prepare CONSCURRENT and VECCURRENT pages for the new half-space into
    which material will be copied.
(3) Scan the C++ stack and process each value on it as an ambiguous potential
    pointer. End up with pin information set on the first word of every item
    in the heap that must not be relocated. Build list (in new space) of
    all the currently pinned items.
(4) For all items identified as pinned evacuate their contents, using the
    list of them to know where they are. Note that data that was pinned last
    time but is not pinned now may still ve referenced in unambiguous ways
    so such pages may not be recycled yet.
(5) Evacuate all unambiguous list-bases.
(6) Now we have a loop that evacuates copied data. There are three actions:
 (6.1) If there is a full page that metarial has been copied into then
       evacuate all in it apart from any pinned things (which have already
       been processed).
 (6.2) If there is material in the VECCURRENT page not yet evacuated then
       deal with some of it. This may end either if the scan point for
       unevacuated data catched up with the fringe or if the scan point
       reaches the end of the page. The latter can happen if performing
       evacuation fills the page (and so a new VECCURRENT will have get
       allocated). Note that the scan will go Chunk by Chunk and Chunks
       containing pinned material must be skipped.
 (6.3) If there is matarial in the CONSCURRENT page not yet evacuated
       then process some, skipping over cells that are marked as pinned.
       As in 6.2 this can stop if things catch up with fringe or reach the
       end of the page.
(7) the old half-space should now be available for re-use. Arrange variously
    as EMPTY, CONSPIN or VECPIN and set up ready for re-use. Ensure that
    everything is ready for the next cycle with the current pin bitmaps moved
    to be the "historical" ones. Note especially that at this stage some
    pages that used to comntain pinned data but where it is no longer pinned
    will have had that data evacuated and so those pages end up empty.

Now let me talk about a higher level. Suppose the total available memory is
N Pages. Then I will grab pages for the mutator until I have 2N/3 in use.
If I perform a GC then it has to transcribe live data into N/3 Pages, and
when it has done that it would be able to allocate a further N/3 before the
next GC was provoked. My expectation is that when working in the extreme
situation where those numbers apply that useful computation and GC copying
costs start to become comparable. If I triggered GC sooner I could cope with
a larger amount of fully live data, but the cost of GC measured against
useful work would escalate.
Now let me consider the fact that some Pages will contain pinned data
while others will not. I am going to expect that only a modest fraction of
all pages contain pinned material, in particular less than N/3 of them. If
that is the case then all ordinary computation can just use pages that start
off fully empty. That simplifies things and speeds them up a bit. When the
GC copies stuff it will first prefer to copy into fully empty pages, and
until memory is really getting full that will always be possible, but as
memory load pushes towards the limit the GC will need to evacuate from
the old heap into Pages of the new heap that contain pinned items. At
least that is in a restricted and controllable state, and in the very
common case where memory is not close to expiring pinned pages will just
be left unused until eventually (one hopes) the ambiguous pointers to within
them dissipate and they can be upgraded to be fully empty pages.
