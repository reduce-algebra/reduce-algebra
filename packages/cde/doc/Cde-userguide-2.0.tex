\documentclass[12pt]{amsart}
\usepackage{xspace}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{color}
\usepackage{mathrsfs}
\usepackage{microtype}
\usepackage{upref}
\usepackage{url}
\usepackage{graphicx}
\usepackage[%dvips,%
pdftitle={},%
pdfauthor={R. Vitolo},%
pdfkeywords={}%
pdfsubject={},%
colorlinks,linkcolor={blue},citecolor={blue},urlcolor={red}%
]{hyperref}

% LENGTHS

\setlength{\hfuzz}{3pt}
%\addtolength{\arraycolsep}{5pt}
%\smartqed
%-----------------------------------------------------------------------------%
% PAGE SIZES
%-----------------------------------------------------------------------------%
\setlength{\headheight}{32pt}
\setlength{\headsep}{29pt}
\setlength{\footskip}{28pt}
\setlength{\textwidth}{444pt}
\setlength{\textheight}{636pt}
\setlength{\marginparsep}{7pt}
\setlength{\marginparpush}{7pt}
\setlength{\oddsidemargin}{4.5pt}
\setlength{\marginparwidth}{55pt}
\setlength{\evensidemargin}{4.5pt}
\setlength{\topmargin}{-15pt}
\setlength{\footnotesep}{8.4pt}
\allowdisplaybreaks[4]

% CLAIMS

\swapnumbers
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

% MACROS

\newcommand{\cprime}{\/{\mathsurround=0pt$'$}}

\newcommand*{\pd}[2]{\mathchoice{\frac{\partial#1}{\partial#2}}
  {\partial#1/\partial#2}{\partial#1/\partial#2}
  {\partial#1/\partial#2}}
\newcommand*{\od}[2]{\mathchoice{\frac{d#1}{d#2}}
  {d#1/d#2}{d#1/d#2}{d#1/d#2}}
\newcommand*{\fd}[2]{\mathchoice{\frac{\delta#1}{\delta#2}}
  {\delta #1/\delta#2}{\delta#1/\delta#2}{\delta#1/\delta#2}}

%    Notation for an expression evaluated at a particular condition.
%    The optional argument can be used to override automatic sizing
%    of the right vert bar, e.g. \eval[\biggr]{...}_{...}
\newcommand{\eval}[2][\right]{\relax
  \ifx#1\right\relax \left.\fi#2#1\rvert}

%    Enclose the argument in vert-bar delimiters.
%    The optional argument can be used to override automatic sizing,
%    e.g. \abs[\bigg]{...}
\newcommand{\envert}[2][\right]{\relax
  \ifx#1\right\relax \left\lvert\else#1\lvert\fi#2#1\rvert}
\let\abs=\envert

%    Enclose the argument in double-vert-bar delimiters:
%    The optional argument can be used to override automatic sizing,
%    e.g. \norm[\bigg]{...}
\newcommand{\enVert}[2][\right]{\relax
  \ifx#1\right\relax \left\lVert\else#1\lVert\fi#2#1\rVert}
\let\matr=\enVert

\newcommand*{\sdim}[2]{#1\vert#2}
\newcommand{\doubell}{\mathcal{L}}

\let\kappa\varkappa
\let\phi\varphi

\newcommand{\hj}{\bar{\jmath}}
\newcommand{\hd}{\bar{d}}
\newcommand{\J}{\bar{\mathcal{J}}}
\newcommand{\Ji}{{\bar{\mathcal{J}}}^{\infty}}
\newcommand{\hL}{\bar{\Lambda}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cJ}{\mathcal{J}}
\newcommand{\g}{\mathfrak{g}}
\newcommand{\hH}{\bar{H}^n}
\newcommand{\Eu}{\mathscr{E}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}

\newcommand{\alg}{\mathcal{F}}

\newcommand{\id}{\mathrm{id}}

\DeclareMathOperator{\CDiff}{\mathcal{C}Dif{}f}
\DeclareMathOperator{\Der}{D}
\DeclareMathOperator{\CL}{CL}
\DeclareMathOperator{\Dv}{D^v}
\DeclareMathOperator{\cl}{cl}
\DeclareMathOperator{\Diff}{Dif{}f}
\DeclareMathOperator{\diff}{dif{}f}
\DeclareMathOperator{\Smbl}{Smbl}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Sym}{Sym}
\DeclareMathOperator{\CoSym}{CoSym}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\pr}{pr}
\DeclareMathOperator{\supp}{supp}
\newcommand*{\CDiffsym}[1]{\CDiff_{(#1)}^{\,\mathrm{sym}}}
\newcommand*{\CDiffself}[1]{\CDiff_{(#1)}^{\,\mathrm{self}}}
\newcommand*{\CDiffskew}[1]{\CDiff_{(#1)}^{\,\mathrm{skew}}}
\newenvironment{system}{\left\{\begin{array}{l}}{\end{array}\right.}

\newcommand{\ddx}[1]{D_x^{#1}}

\newcommand{\cde}{CDE\xspace}
\newcommand{\cdiff}{CDIFF\xspace}
\newcommand{\REDUCE}{\texttt{Reduce}\xspace}
\newcommand{\reduce}{\REDUCE}
\newcommand{\crack}{CRACK\xspace}
\newcommand{\cdiffop}{$\mathcal{C}$-differential operator\xspace}
\newcommand{\cdiffops}{$\mathcal{C}$-differential operators\xspace}

%    Cyrillic letter \`E for use in math. mode
%    (from the Univ. of Washington Cyrillic font)
%\DeclareFontFamily{OT1}{wncyi}{}
%\DeclareFontShape{OT1}{wncyi}{m}{it}{
%   <5> <6> <7> <8> <9> gen * wncyi
%   <10> <10.95> <12> <14.4> <17.28> <20.74> <24.88> wncyi10
%  }{}
%\DeclareSymbolFont{cyrletters}{OT1}{wncyi}{m}{it}
%\DeclareSymbolFontAlphabet{\cyrmath}{cyrletters}
%\DeclareMathSymbol{\re}{\cyrmath}{cyrletters}{"03}
%\newcommand{\Ev}{\re}
\newcommand{\Ev}{E}
\newcommand{\EulerOperator}{\mathscr{E}}

%    HyperTeX commands
\providecommand{\href}[2]{#2}
\providecommand{\urlprefix}{URL }
%\newcommand*{\email}[1]{\href{mailto:#1}{\begingroup \urlstyle{rm}\Url{#1}}}
\providecommand*{\eprint}[2][]{\href{http://arXiv.org/abs/#2}%
{\begingroup \Url{arXiv:#2}}}

%\makeatletter
%\renewcommand{\@fnsymbol}[1]{}
%\makeatother

%\markboth{Variational brackets in the geometry of PDEs}%
%{P.H.M. Kersten, I.S. Krasil\cprime shchik, A.M.
%  Verbovetsky, R. Vitolo}

\newcommand{\nota}[2]{\color{red}[{Mark: #1}\par{#2}]\color{black}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title[\cde user guide]%
{\cde: a Reduce package for integrability of PDEs
  \\
  version 2.0}


\author[R. Vitolo]{R. Vitolo}
\address{R. Vitolo\\ Dept.\ of Mathematics and Physics
  ``E. De Giorgi'', Universit\`a del Salento \\ via per Arnesano, 73100 Lecce,
  Italy} \email{raffaele.vitolo@unisalento.it}

\date{2015 October -- \cde version: 2.0}

\thanks{}

\keywords{\reduce, Hamiltonian operators, symplectic operators, recursion
  operators, generalized symmetries, higher symmetries, conservation laws,
  nonlocal variables.}

\subjclass[2010]{37Kxx}

\begin{abstract}
  We describe \cde, a \reduce package devoted to differential-geometric
  computations on Differential Equations (DEs, for short).
  The package is included in the official \reduce sources in Sourceforge
  \cite{reduce} and it is also distributed on the Geometry of Differential
  Equations web site \url{http://gdeq.org} (GDEQ for short).

  We start from an installation guide for Linux and Windows. Then we focus on
  concrete usage recipes for computations in the geometry of differential
  equations: higher symmetries, conservation laws, Hamiltonian operators and
  their Schouten bracket, recursion operators. All programs discussed here are
  shipped together with this manual and can be found in the \reduce sources or
  at the GDEQ website. The mathematical theory on which computations are based
  can be found in refs.~\cite{Many,KKV}. A book on integrable systems and \cde
  is currently being written \cite{KVV-book} with more examples and more
  detailed explanations about the mathematical part.
\end{abstract}

\maketitle

\tableofcontents

\section{Introduction: why \cde?}
\label{sec:why-cde}

This brief guide refers to using \cde, a \reduce package for
differential-geometric computations for DEs. The package aims at defining
differential operators in total derivatives and computing with them. Such
operators are called \emph{$\mathcal{C}$-differential operators} (see
\cite{Many}). \cde runs in the computer algebra system \reduce and depends on
the \reduce package \cdiff for constructing total derivatives. Recently,
\reduce 3.8 became free software, and can be downloaded here \cite{red}. This
was an important motivation for making our computations accessible to a wider
public, also through this user guide.

The development of the \cdiff package was started by Gragert and Kersten for
symmetry computations in DEs. Then \cdiff was partly rewritten and extended by
Roelofs and Post. The \cdiff package consists of 4 files, but only the main
three files are documented \cite{svec,integ,tools}. This software and the
related documentation can be found in both the \reduce sources and the Geometry
of Differential Equations (GDEQ for short) web site \cite{gdeq}.

There are already several software packages that may compute symmetries and
conservation laws; many of them run on Mathematica or Maple. Those who run on
\reduce were written by M.C. Nucci \cite{nucci1,nucci2}, F. Oliveri
(\textsc{ReLie}, \cite{relie}), F. Schwartz (SPDE, \reduce official
distribution) T. Wolf (APPLYSYM and CONLAW in the official \reduce\
distribution, \cite{wolfcl,wolfsy,wbde,wolfsy0}).

The development of \cde started from the idea that a computer algebra tool
for the investigation of integrability-related structures of PDEs still does
not exist in the public domain. We are only aware of a Mathematica package that
may find recursion operators under quite restrictive hypotheses \cite{BH10}.

\cde is especially designed for computations of integrability-related
structures (such as Hamiltonian, symplectic and recursion operators) for
systems of differential equations with an arbitrary number of independent or
dependent variables. On the other hand \cde is also capable of (generalized)
symmetry and conservation laws computations.  The aim of this manual is to
introduce the reader to computations of integrability related structures using
\cde.

The current version of \cde, 2.0, has the following features:
\begin{enumerate}
\item is able to do standard computations in integrable systems like
  determining systems for generalized symmetries and conservation
  laws. However, \cde has not been programmed with this purpose in mind.
\item \cde is able to compute linear overdetermined systems of partial
  differential equations whose solutions are Hamiltonian, symplectic or
  recursion operators. Such equations may be solved by different techniques;
  one of the possibilities is to use CRACK, a \REDUCE package for solving
  overdetermined systems of PDEs \cite{crack}.
\item \cde can compute linearization (or Fr\'echet derivatives) of vector
  functions and adjoints of differential operators.
\item \cde is able to compute Schouten brackets between multivectors. This can
  be used \emph{eg} to check Hamiltonianity of an operator or to check their
  compatibility.

\end{enumerate}
At the moment the papers
\cite{fpv,fpv2,KerstenKrasilshchikVerbovetskyVitolo:HSGP,KKV-SPT-2011,pv,sv}
have been written using \cde, and more research by \cde on integrable systems
is in progress.
A book on integrable systems and \cde is currently being written
\cite{KVV-book} with more examples and more detailed explanations about the
mathematical part.

The readers are warmly invited to send questions, comments, etc., both on the
computations and on the technical aspects of installation and configuration of
\reduce, to the author of this document.

\textbf{Acknowledgements.} I'd like to thank Paul H.M. Kersten, who explained
to me how to use the original \cdiff package for several computations of
interest in the Geometry of Differential Equations. When I started writing \cde
I was substantially helped by A.C. Norman in understanding many features of
Reduce which were deeply hidden in the source code and not well
documented. This also led to writing a manual of Reduce's internals for
programmers \cite{inside}. Moreover, I'd like to thank the developers of the
\REDUCE mailing list for their prompt replies with solutions to my problems.
On the mathematical side, I would like to thank J.S. Krasil'shchik and
A.M. Verbovetsky for constant support and stimulating discussions which led me
to write the software. Thanks are also due to B.A. Dubrovin, M. Casati,
E.V. Ferapontov, P. Lorenzoni, M. Marvan, V. Novikov, A. Savoldi, A. Sergyeyev,
M.V. Pavlov for many interesting discussions.

\section{Installation}
\label{sec:installation}

In order to use the \cde package it is enough to have a recent version of
\reduce with both the \cde and the \cdiff packages installed.

We stress that \emph{most of the technical difficulties related to installation
  and configuration are due to the lack of a \reduce installer. This problem
  should be solved in the near future. There is an experimental \reduce
  installer for Windows on Sourceforge, interested users might wish to try it.}

\subsection{Installation of Reduce}
\label{sec:installation-reduce}

In order to install \reduce one can download the Windows installer
or download a precompiled binary distribution from here \cite{reduce}. However,
please make sure that the version that you are downloading has been compiled
\emph{later} than October 2015, or you will not get \cde in it. If you are
ready to recompile \reduce, please consider the text \cite{inside} for
instructions on how to do it in different operating systems.

From now on we will assume that the binary executable of \reduce is in the path
of the executables of your operating system. A typical location in Linux would
be \texttt{/usr/local/bin}. You might put a link instead of the binary
executable.

A \reduce program using \cde package can be written with any text editor; it
is customary to use the extension \texttt{.red} for \reduce programs, like
\texttt{program.red}. If you wish to run your program, just run the \reduce
executable. After starting \reduce, you would see something like
\begin{verbatim}
Reduce (Free CSL version), 01-Oct-15 ...

1:
\end{verbatim}
At the prompt \texttt{1:} write \texttt{in "program.red";}. Of course, if the
program file \texttt{program.red} \emph{is not} in the place where the \reduce
executable is, you should indicate the full path of the program, and this
depends on your system. In Linux, assuming that you are the user
\texttt{user} and your program is in the subdirectory
\texttt{Reduce/computations} of your home directory, you have something like
\begin{verbatim}
  in "/home/user/Reduce/computations/program.red";
\end{verbatim}
In Windows, assuming that you are the user
\texttt{user} and your program is in the subdirectory
\texttt{Reduce$\backslash$computations} of the Desktop folder, you would write
\begin{verbatim}
  in "C:\Documents and Settings\user\Desktop\Reduce
\computations\program.red";
\end{verbatim}
Remember that each time you run \reduce from a command shell, \reduce
inherits your current path from the shell unless you use an absolute path as
above. However, if you start \reduce with the graphical interface (see below)
you can always use the leftmost menu item \texttt{File>Open\dots} in order to
avoid to write down the whole absolute path.

\subsection{Choice of an editor for writing Reduce programs}
\label{sec:inst-reduce-ide}

Now, let us deal with the problem of writing \reduce programs.

Generally speaking, any text editor can be used to write a \reduce program. A
more suitable choice is an editor for programming languages. Such editors exist
in Linux and Windows, a list can be found here \cite{ed}.

A suggested text editor in Windows is \texttt{notepad++}. This editor is easy
to install, it has support for many programming languages (but \emph{not} for
\reduce!), and has a GPL free license, see \cite{noteppp}. Similar tools in
Linux are \texttt{kwrite} and \texttt{gedit}.

The IDE (Integrated Development Environment) of choice of the author for
developing programs and running them inside the editor itself exists for the
great text editor \texttt{emacs}, which runs in all operating systems, and in
particular Linux and Windows. We stress that an IDE makes the
developing-running-debugging cycle much faster because every step is performed
in the same environment. Another IDE which has \reduce capabilities is GNU
TeXmacs, see \url{http://www.texmacs.org}.

Installation of \texttt{emacs} in Linux is quite smooth, although it depends on
the Linux distribution; usually it is enough to select the package
\texttt{emacs} in your favourite package management tool, like
\texttt{aptitude, synaptic,} or \texttt{kpackage}.  In order to install
\texttt{emacs} on Windows one has to work a little bit more. See here
\cite{emacswin} for more information.  Assuming that \texttt{emacs} it is
installed and working, the \reduce IDE for \texttt{emacs} can be found here
\cite{redide}.  We refer to their guide for the installation (the procedure is
the same for both Linux and Windows). I tested the IDE with emacs 23.2.1 under
Debian-based Linux systems (Debian Etch and Squeeze 32-bit and 64-bit, Ubuntu
11.04 64-bit) and Windows XP and it works fine for me.

Suppose you have \texttt{emacs} and its \reduce IDE installed, then there is a
last configuration step that will make \texttt{emacs} and \reduce work together.
Namely, when opening for the first time a \reduce program file with
\texttt{emacs}, go to the \texttt{REDUCE>Customize\dots} menu item and locate
the `\reduce run Program' item. This item contains the command which is issued
by \texttt{emacs} from the \reduce IDE when the menu item \texttt{Run REDUCE>Run
  REDUCE} is selected. Change the command to:
  \begin{itemize}
  \item under Linux (user and location as above):
   \begin{verbatim}
    reduce -w
    \end{verbatim}
  \item under Windows (user and locations as above):
   \begin{verbatim}
    reduce.exe
    \end{verbatim}
  \end{itemize}
This setting will run \reduce inside \texttt{emacs}. If you prefer the (slower)
graphical interface to \reduce, remove `\texttt{-w}'. Note that the graphical
interface will produce \LaTeX\ output, making it much more readable. This
behaviour can be turned off in the graphical interface by issuing the command
\texttt{off fancy;}.

\section{Working with CDE}
\label{sec:working-with-cde}

All programs that we will discuss in this manual can be found inside the
subfolder \texttt{examples} of the main directory of \cde.  There
are some conventions that I adopted on writing programs which use \cde.
\begin{itemize}
\item Test files have the following names:
  \begin{center}
    \texttt{equationname\_typeofcomputation.red}
  \end{center}
  where \texttt{equationname} stands for the shortened name of the equation
  (\emph{e.g.} Ko\-rteweg--de Vries is always indicated by \texttt{kdv}), and
  \texttt{typeofcomputation} stands for the type of geometric object which is
  computed with the given file, for example symmetries, Hamiltonian operators,
  etc.. This string also includes a version number. The extension \texttt{.red}
  will tell \texttt{emacs} to load the reduce-ide mode (provided you made the
  installation steps described in the reduce-ide guides).
\item More specific information, like the date and more details on the
  computation done in each version, are included as comment lines at the very
  beginning of each file.
\end{itemize}
If you use a generic editor, as soon as you are finished writing a program, you
may run it from within \reduce by following the instructions in the previous
section.

In \texttt{emacs} with \reduce IDE it is easier: issuing the command
\texttt{M-x run-reduce} (or choosing the menu item \texttt{Run REDUCE>Run
  REDUCE}) will split the window in two halves and start \reduce in the bottom
half. You may use either CSL or PSL \reduce: they are two different
interpreters of the low-level programming language of \reduce, Standard Lisp.
\reduce shows up the type of interpreter at startup,
see~\ref{sec:installation-reduce}. At the moment, tests by \cde computations
show that the CSL interpreter is considerably faster than the PSL interpreter.

Then you may load the program file that you were editing (suppose
that its name is \texttt{program.red}) by issuing \texttt{in "program.red";} at
the \reduce prompt. In fact, \texttt{emacs} lets \reduce assume as its working
directory the directory of the file that you were editing.

\textbf{NOTE:} \emph{at the time of writing the package \cde is being included
  into the main \REDUCE source tree. So, it is not likely that it will be
  contained in any old binary distribution. If this is the case, please put
  your program file in the main \cde directory is, in order to allow \REDUCE to
  find the main file \texttt{cde.red} and then all others.}

Results of a computation consist of the values of one or more unknown. Suppose
that the unknown's name is \texttt{sym}, and assume that, after a computation,
you wish to save the values of \texttt{sym}, possibly for future use from within
\reduce. Issue the following \reduce commands (of course, after you finish your
computations!):
\begin{verbatim}
off nat;
out "file_res.red";
sym:=sym;
shut "file_res.red";
on nat;
\end{verbatim}
The above commands will write the content of \texttt{sym} into the file
\texttt{file\_res.red}, where \texttt{file} stands for a filename which
follows the above convention. The command \texttt{off nat;} is needed in order
to save the variable in a format which could be imported in future \reduce
sessions. If you wish to translate your results in \LaTeX, see the package
\texttt{tri} and its own documentation.

Working remotely with \reduce is not difficult and it is highly recommended for
big computations that a server can run more efficiently and without
interruptions. A method of choice to do this is described by the following
steps:
\begin{enumerate}
\item login to the remote server with \texttt{ssh};
\item start \texttt{emacs} as a daemon on the server by the command
  \texttt{emacs --daemon} (only from version 23.1!);
\item run \texttt{emacsclient -c file.red}. That program will connect to the
  \texttt{emacs} daemon and open the requested file.
\item run \reduce (if you installed the reduce IDE everything is easier,
  otherwise you should open a shell within emacs and issue the command
  \texttt{reduce});
\item exit \texttt{emacsclient} normally (C-x C-c). This will not kill the
  daemon, that will keep your computation running until the end.
\item login again when you wish to check the computation.
\end{enumerate}

In next sections we will describe some examples of computations with
\cde. The parts which are shared between all examples are described only
once. We stress that all computations presented in this document can be
downloaded at the GDEQ website \cite{gdeq}, and that they are run in the
\reduce environment by typing \texttt{in "program.red";} at the \reduce prompt,
as explained above. Moreover, all examples can be run at once by the shell
script \texttt{cdiff.sh} to test if the system is working properly and results
are the same as obtained previously.

Each computation consists of two parts: setting up the jet space and the
equation, and solving the problem using suitable ansatz for the unknown
functions. We will emphasize this division only in the first example.

\textbf{Remark.} The mathematical framework on which the computations are based
can be found in \cite{Many}.

\section{Jet space of even and odd variables,
  and total derivatives}
\label{sec:jet-space-even}

The mathematical theory for jets of even (\emph{ie} standard) variables and
total derivatives can be found in \cite{Many,Olv}.

Let us consider the space $\mathbb{R}^n\times\mathbb{R}^m$, with coordinates
$(x^\lambda,u^i)$, $1\leq \lambda\leq n$, $1\leq i\leq m$. We say $x^\lambda$
to be \emph{independent variables} and $u^i$ to be \emph{dependent variables}.
Let us introduce the \emph{jet space} $J^r(n,m)$. This is the space with
coordinates $(x^\lambda,u^i_\sigma)$, where $u^i_\sigma$ is defined as follows.
If $s\colon \R^n\to \R^m$ is a differentiable function, then
\begin{displaymath}
  u^i_\sigma\circ s(x)=\frac{\partial^{|\sigma|}(u^i\circ s)}
  {(\partial x^1)^{\sigma_1}\cdots (\partial x^n)^{\sigma_n}}.
\end{displaymath}
Here $\sigma=(\sigma_1,\ldots,\sigma_n)\in\N^n$ is a multiindex. We set
$|\sigma|=\sigma_1+\cdots+\sigma_n$. If $\sigma=(0,\ldots,0)$ we set
$u^i_\sigma=u^i$.

\cde is first of all a program which is able to create a \emph{finite order jet
  space} inside \reduce. To this aim, issue the command
\begin{verbatim}
in "cde.red";
\end{verbatim}
Then, \cde needs to know the variables and the maximal
order of derivatives. The input can be organized as in the following example:
\begin{verbatim}
indep_var:={x,t}$
dep_var:={u,v}$
total_order:=10$
\end{verbatim}
Here
\begin{itemize}
\item \texttt{indep\_var} is the list of independent variables;
\item \texttt{dep\_var} is the list of dependent variables;
\item \texttt{total\_order} is the maximal order of derivatives.
\end{itemize}

Two more parameters can be set for convenience:
\begin{verbatim}
statename:="jetuv_state.red"$
resname:="jetuv_res.red"$
\end{verbatim}
These are the name of the output file for recording the internal state of the
program \texttt{cde.red} (and for debugging purposes), and the name of the file
containing results of the computation.

The main routine in \texttt{cde.red} is called as follows:
\begin{verbatim}
cde({indep_var,dep_var,{},total_order},{})$
\end{verbatim}
Here the two empty lists are placeholders; they are important for
computations with odd variables/differential equations.
The function $\texttt{cde}$ defines derivative symbols of the type:
\begin{verbatim}
u_x,v_t,u_2xt,v_xt,v_2x3t,...
\end{verbatim}
Note that the symbol \texttt{v\_tx} does not exist in the jet space. Indeed,
introducing all possible permutations of independent variables in indices would
increase the complexity and slow down every computation.

Two lists generated by \cde can be useful: \texttt{all\_der\_id} and
\texttt{all\_odd\_id}, which are, respectively, the lists of identifiers of all
even and odd variables.

Other lists are generated by \cde, but they are accessible in
\reduce symbolic mode only. Please check the file \texttt{global.txt} to know
the names of the lists.

It can be useful to inspect the output generated by the function \texttt{cde}
and the above lists in particular.  All that data can be saved by the function:
\begin{verbatim}
save_cde_state(statename)$
\end{verbatim}

\cde has a few procedures involving the jet space, namely:
\begin{itemize}
\item \texttt{jet\_fiber\_dim(jorder)} returns the number of derivative
  coordinates $u^i_\sigma$ with $|\sigma|$ equal to \texttt{jorder};
\item \texttt{jet\_dim(jorder)} returns the number of derivative
  coordinates $u^i_\sigma$ with $0\leq|\sigma|$ and $|\sigma|$ equal to
  \texttt{jorder};
\item \texttt{selectvars(par,orderofder,depvars,vars)} returns all derivative
  coordinates (even if \texttt{par=0}, odd if \texttt{par=1}) of order
  \texttt{orderofder} of the list of dependent variables \texttt{depvars} which
  belong to the set of derivative coordinates \texttt{vars}.
\end{itemize}

The function \texttt{cde} defines total derivatives truncated at the order
\texttt{total\_order}. Their coordinate
expressions are of the form
\begin{equation}
  \label{eq:2}
  D_\lambda=\pd{}{x^\lambda} +
  u^i_{\boldsymbol{\sigma}\lambda}\pd{}{u^i_{\boldsymbol{\sigma}}},
\end{equation}
where $\boldsymbol{\sigma}$ is a multiindex.

The total derivative of an argument $\varphi$ is invoked as follows:
\begin{verbatim}
td(phi,x,2);
td(phi,x,t,3);
\end{verbatim}
the syntax closely follows \reduce's syntax for standard derivatives
\texttt{df}; the above expression translates to $D_xD_x\varphi$, or
$D_{\{2,0\}}\varphi$ in multiindex notation.

When in total derivatives there is a coefficient of order higher than maximal
this is replaced by the identifier \texttt{letop}, which is a function that
depends on independent variables. If such a function (or its derivatives)
appears during computations it is likely that we went too close to the highest
order variables that we defined in the file. All results of computations are
scanned for the presence of such variables by default, and if the presence of
\texttt{letop} is detected the computation is stopped with an error
message. This usually means that we need to extend the order of the jet space,
just by increasing the number \texttt{total\_order}.

Note that in the folder containing all examples there is also a shell script,
\texttt{rrr.sh} (works only under \texttt{bash}, a GNU/Linux command
interpreter) which can be used to run reduce on a given \cde program.
When an error message about \texttt{letop} is issued the script
reruns the computation with a new value of \texttt{total\_order} one unity
higher than the previous one.

The function that checks an expression for the presence of \texttt{letop} is
\texttt{check\_letop}.  If you wish to switch off this kind of check in order
to increase the speed, the switch \texttt{checkord} must be set off:
\begin{verbatim}
off checkord;
\end{verbatim}

The computation of total derivatives of a huge expression can be extremely time
and resources consuming. In some cases it is a good idea to disable the
expansion of the total derivative and leave an expression of the type $D_\sigma
\varphi$ as indicated. This is achieved by the command
\begin{verbatim}
noexpand_td();
\end{verbatim}
If you wish to restore the default behaviour, do
\begin{verbatim}
expand_td();
\end{verbatim}

\cde can also compute on jets of supermanifolds. The theory can be found in
\cite{IVV,KKV,KrVe-JGP-2011}. The input can be organized as follows:
\begin{verbatim}
indep_var:={x,t}$
dep_var:={u,v}$
odd_var:={p,q}
total_order:=10$
\end{verbatim}
Here \texttt{off\_var} is the list of odd variables. The call
\begin{verbatim}
cde({indep_var,dep_var,odd_var,total_order},{})$
\end{verbatim}
will create the jet space of the supermanifold described by the independent
variables and the even and odd dependent variables, up to the order
\texttt{total\_order}. Total derivatives truncated at the order
\texttt{total\_order} will also include odd derivatives:
\begin{equation}
  \label{eq:201}
  D_\lambda=\pd{}{x^\lambda} +
  u^i_{\boldsymbol{\sigma}\lambda}\pd{}{u^i_{\boldsymbol{\sigma}}}
    + p^i_{\boldsymbol{\sigma}\lambda}\pd{}{p^i_{\boldsymbol{\sigma}}},
\end{equation}
where $\boldsymbol{\sigma}$ is a multiindex. The considerations on
expansion and \texttt{letop} apply in this case too.

Odd variables can appear in anticommuting products; this is represented as
\begin{verbatim}
ext(p,p_2xt),ext(p_x,q_t,q_x2t),...
\end{verbatim}
where \texttt{ext(p\_2xt,p) = - ext(p,p\_2xt)} and the variables are arranged
in a unique way terms of an internal ordering. Indeed, the internal
representation of odd variables and their products (not intended for normal
users!) is
\begin{verbatim}
ext(3,23),ext(1,3,5),...
\end{verbatim}
as all odd variables and their derivatives are indexed by integers.
Note that \texttt{p} and \texttt{ext(p)} are just the same. The odd product of
two expressions $\varphi$ and $\psi$ is achieved by the \cdiff function
\begin{verbatim}
super_product(phi,psi);
\end{verbatim}
The derivative of an expression $\varphi$ with respect to an odd variable $p$
is achieved by
\begin{verbatim}
df_odd(phi,p);
\end{verbatim}

\section{Differential equations in even and odd variables}
\label{sec:diff-equat-even}

We now give the equation in the form of one or more derivatives equated to
right-hand side expressions. The left-hand side derivatives are called
\emph{principal}, and the remaining derivatives are called
\emph{parametric}\footnote{This terminology dates back to Riquier, see
  \cite{Mar}}. Parametric coordinates are coordinates on the equation manifold
and its differential consequences, and principal coordinates are determined
by the differential equation and its differential consequences.  For scalar
evolutionary equations with two independent variables parametric derivatives
are of the type $(u,u_x,u_{xx},\ldots)$.  Note that the system must be in
passive orthonomic form; this also means that there will be no nontrivial
integrability conditions between parametric derivatives. (Lines
beginning with \texttt{\%} are comments for \reduce.) The input is formed as
follows (Burger's equation).
\begin{verbatim}
% left-hand side of the differential equation
principal_der:={u_t}$
% right-hand side of the differential equation
de:={u_2x+2*u*u_x}$
\end{verbatim}
Systems of PDEs are input in the same way: of course, the above two lists must
have the same length. See \ref{sec:comp-syst-pdes} for an example.

The main routine in \texttt{cde.red} is called as follows:
\begin{verbatim}
cde({indep_var,dep_var,{},total_order},
   {principal_der,de,{},{}})$
\end{verbatim}
Here the three empty lists are placeholders; they are important for
computations with odd variables. The function \texttt{cde}
computes principal and parametric derivatives of even and odd variables, they
are stored in the lists \texttt{all\_parametric\_der, all\_principal\_der, 
all\_parametric\_odd, all\_principal\_odd}.

The function \texttt{cde} also defines total derivatives truncated at the order
\texttt{total\_order} and restricted on the (even and odd) equation; this means
that total derivatives are tangent to the equation manifold. Their coordinate
expressions are of the form
\begin{equation}
  \label{eq:212}
  D_\lambda=\pd{}{x^\lambda}+\sum_{u^i_{\boldsymbol{\sigma}}\
    \text{parametric}}u^i_{\boldsymbol{\sigma}\lambda}\pd{}{u^i_{\boldsymbol{\sigma}}}
  + \sum_{p^i_{\boldsymbol{\sigma}}\
    \text{parametric}}p^i_{\boldsymbol{\sigma}\lambda}\pd{}{p^i_{\boldsymbol{\sigma}}},
\end{equation}
where $\boldsymbol{\sigma}$ is a multiindex.  It can happen that
$u^i_{\boldsymbol{\sigma}\lambda}$ (or $p^i_{\boldsymbol{\sigma}\lambda}$) is
principal and must be replaced with differential consequences of the equation.
Such differential consequences are called \emph{primary differential
  consequences}, and are computed; in general they will depend on other,
possibly new, differential consequences, and so on. Such newly appearing
differential consequences are called \emph{secondary differential
  consequences}. If the equation is in passive orthonomic form, the system of
all differential consequences (up to the maximal order \texttt{total\_order})
must be solvable in terms of parametric derivatives only. The function
\emph{cde} automatically computes all necessary and sufficient differential
consequences which are needed to solve the system. The solved system is
available in the form of \reduce let-rules in the variables
\texttt{repprincparam\_der} and \texttt{repprincparam\_odd}.

The syntax and properties (expansion and \texttt{letop}) of total derivatives
remain the same. For exmaple:
\begin{verbatim}
td(u,t);
\end{verbatim}
returns
\begin{verbatim}
u_2x+2*u*u_x;
\end{verbatim}

It is possible to deal with mixed systems on eve and odd variables. For
example, in the case of Burgers equation we can input the linearized equation
as a PDE on a new odd variable as follows (of course, in addition to what has
been defined before):
\begin{verbatim}
odd_var:={q}$
principal_odd:={q_t}$
de_odd:={q_2x + 2*u_x*q + 2*u*q_x}$
\end{verbatim}
The main routine in \texttt{cde.red} is called as follows:
\begin{verbatim}
cde({indep_var,dep_var,odd_var,total_order},
   {principal_der,de,principal_odd,de_odd})$
\end{verbatim}

\section{Calculus of variations}
\label{sec:calculus-variations}

\cde can compute variational derivatives of any function (usually a Lagrangian
density) or superfunction $\mathcal{L}$. We have the following coordinate
expression
\begin{equation}
  \label{eq:9}
  \fd{\mathcal{L}}{u^i} = (-1)^{|\sigma|}D_\sigma\pd{\mathcal{L}}{u^i_\sigma},
  \quad
    \fd{\mathcal{L}}{p^i} = (-1)^{|\sigma|}D_\sigma\pd{\mathcal{L}}{p^i_\sigma}
\end{equation}
which translates into the \cde commands
\begin{verbatim}
pvar_df(0,lagrangian_dens,ui);
pvar_df(1,lagrangian_dens,pi);
\end{verbatim}
where
\begin{itemize}
\item the first argument can be $0$ or $1$ and is the parity of the variable
  \texttt{ui} or \texttt{pi};
\item \texttt{lagrangian\_dens} is $\mathcal{L}$;
\item \texttt{ui} or \texttt{pi} are the given dependent variables.
\end{itemize}
The Euler operator computes variational derivatives with respect to all even
and odd variables in the jet space, and arranges them in a list of two lists,
the list of even variational derivatives and the list of odd variational
derivatives. The command is
\begin{verbatim}
euler_df(lagrangian_dens);
\end{verbatim}
All the above is used in the definition of Schouten brackets, as we will see in
Subsection~\ref{sec:mathc-diff-oper-odd}.

\section{$\mathcal{C}$-differential operators}
\label{sec:mathc-diff-oper-1}

Linearizing (or taking the Fr\'echet derivative) of a vector function that
defines a differential equation yields a differential operator in total
derivatives. This operator can be restricted to the differential equation,
which may be regarded as a differential constraint; the kernel of the
restricted operator is the space of all symmetries (including higher or
generalized symmetries) \cite{Many,Olv}.

The formal adjoint of the linearization operator yields by restriction to the
corresponding differential equation a differential operator whose kernel
contains all characteristic vectors or generating functions of conservation
laws \cite{Many,Olv}.

Such operators are examples of $\mathcal{C}$-differential operators. The (still
incomplete) \reduce implementation of the calculus of
$\mathcal{C}$-differential operators is the subject of this section.

\subsection{$\mathcal{C}$-differential operators}
\label{sec:mathc-diff-oper}

Let us consider the spaces
\begin{displaymath}
  P=\{\varphi\colon J^r(n,m)\to \R^k\},\qquad Q=\{\psi\colon J^r(n,m)\to \R^s\}.
\end{displaymath}
A \emph{$\mathcal{C}$-differential operator} $\Delta\colon P\to Q$ is defined
to be a map of the type
\begin{equation}\label{eq:4}
  \Delta(\varphi) = (\sum_{\sigma, i}a^{\sigma j}_i D_\sigma \varphi^i),
\end{equation}
where $a^{\sigma j}_i$ are differentiable functions on $J^r(n,m)$, $1\leq i\leq
k$, $1\leq j\leq s$. The \emph{order} of $\delta$ is the highest length of
$\sigma$ in the above formula.

We may consider a generalization to $k$-\emph{$\mathcal{C}$-differential
  operators} of the type
\begin{multline}\label{eq:7}
  \Delta\colon P_1\times\cdots\times P_h \to Q\\
  \Delta(\varphi_1,\dots,\varphi_h) =
  (\sum_{\sigma_1,\ldots,\sigma_h, i_1,\ldots,
    i_h}a^{\sigma_1,\ldots,\sigma_h,\ j}_{i_1\cdots i_h} D_{\sigma_1}
  \varphi_1^{i_1}\cdots D_{\sigma_h}\varphi_h^{i_h}),
\end{multline}
where the enclosing parentheses mean that the value of the operator is a vector
function in $Q$.

A \cdiffop in \cde must be declared as follows:
\begin{verbatim}
mk_cdiffop(opname,num_arg,length_arg,length_target)
\end{verbatim}
where
\begin{itemize}
\item \texttt{opname} is the name of the operator;
\item \texttt{num\_arg} is the number of arguments \emph{eg} $k$ in
  \eqref{eq:7};
\item \texttt{length\_arg} is the list of lengths of the arguments: \emph{eg}
  the length of the single argument of $\Delta$ \eqref{eq:4} is $k$, and the
  corresponding list is \texttt{\{k\}}, while in \eqref{eq:7} one needs a list
  of $k$ items \texttt{\{k\_1,\dots,k\_h\}}, each corresponding to number of
  components of the vector functions to which the operator is applied;
\item \texttt{length\_target} is the numer of components of the image vector
  function.
\end{itemize}
The syntax for one component of the operator \texttt{opname} is
\begin{verbatim}
  opname(j,i1,...,ih,phi1,...,phih)
\end{verbatim}
The above operator will compute
\begin{equation}
  \label{eq:10}
  \Delta(\phi_1,\dots,\phi_h) = \sum_{\sigma_1,\ldots,\sigma_h}
  a^{\sigma_1,\ldots,\sigma_h,\ j}_{i_1\cdots i_h}
  D_{\sigma_1} \phi_1^{i_1}\cdots D_{\sigma_h}\phi_h^{i_h},
\end{equation}
for fixed integer indices $i_1$,\dots,$i_h$ and $j$.

\medskip

There are several operations which involve differential operators. Obviously
they can be summed and multiplied by scalars.

An important example of $\mathcal{C}$-differential operator is that of
\emph{linearization}, or \emph{Fr\'echet derivative}, of a vector function
\begin{displaymath}
    F\colon J^r(n,m) \to \R^k.
\end{displaymath}
This is the operator
\begin{displaymath}
  \ell_F\colon \varkappa \to P ,\quad \varphi \mapsto
  \sum_{\sigma, i}\pd{F^k}{u^i_\sigma}D_\sigma\varphi^i,
\end{displaymath}
where $\varkappa = \{ \varphi \colon J^r(n,m) \to \R^m \}$ is the space of
\emph{generalized vector fields on jets} \cite{Many,Olv}.

Linearization can be extended to an operation that, starting from a
$k$-$\mathcal{C}$-differential operator, generates a
$k+1$-$\mathcal{C}$-differential operator as follows:
\begin{displaymath}
  \ell_{\Delta}(p_1,\dots,p_k,\varphi) =
  (\sum_{\sigma,\sigma_1,\ldots,\sigma_k, i,i_1,\ldots,i_k}
  \frac{\partial a^{\sigma_1,\ldots,\sigma_k,\ j}_{i_1\cdots i_k}}{\partial
    u^i_\sigma}
  D_{\sigma}\varphi^i D_{\sigma_1}p_1^{i_1}\cdots D_{\sigma_k}p_k^{i_k})
\end{displaymath}
(The above operation is also denoted by $\ell_{\Delta,p_1,\dots,p_k}(\varphi)$.)

At the moment, \cde is only able to compute the linearization of a vector
function (Section~\ref{sec:linadj}).

Given a \cdiffop $\Delta$ like in \eqref{eq:4} we can define its \emph{adjoint}
as
\begin{equation}\label{eq:5}
  \Delta^*((q_j)) =
  (\sum_{\sigma, i}  (-1)^{|\sigma|} D_\sigma(a^{\sigma j}_i q_j)).
\end{equation}
Note that the matrix of coefficients is transposed. Again, the coefficients of
the adjoint operator can be found by computing $\Delta^*(x^\sigma e_j)$ for
every basis vector $e_j$ and every count $x^\sigma$, where $|\sigma|\leq r$,
and $r$ is the order of the operator. This operation can be generalized to
\cdiffops with $h$ arguments.

At the moment, \cde can compute the adjoint of an operator with one argument
(Section~\ref{sec:linadj}).

Now, consider two operators $\Delta\colon P\to Q$ and $\nabla\colon Q\to R$.
Then the composition $\nabla\circ\Delta$ is again a $\mathcal{C}$-differential
operator. In particular, if
\begin{displaymath}
  \Delta(p) = (\sum_{\sigma, i}a^{\sigma j}_i D_\sigma p^i),\quad
  \nabla(q) = (\sum_{\tau, j}b^{\tau k}_j D_\tau q^j),
\end{displaymath}
then
\begin{displaymath}
  \nabla\circ\Delta(p) =
  (\sum_{\tau, j}b^{\tau k}_j D_\tau (\sum_{\sigma, i}a^{\sigma j}_i D_\sigma p^i))
\end{displaymath}
This operation can be generalized to
\cdiffops with $h$ arguments.

There is another important operation between \cdiffops with $h$ arguments: the
\emph{Schouten bracket} \cite{Many}. We will discuss it in next Subsection, in
the context of another formalism, where it takes an easier form \cite{KKV}.

\subsection{$\mathcal{C}$-differential operators as superfunctions}
\label{sec:mathc-diff-oper-odd}

In the papers \cite{IVV,KKV} (and independently in \cite{getz}) a scheme for
dealing with (skew-adjoint) variational multivectors was devised. The idea was
that operators of the type \eqref{eq:7} could be represented by homogeneous
vector superfunctions on a supermanifold, where odd coordinates $q^i_\sigma$
would correspond to total derivatives $D_\sigma\phi^i$. 

The isomorphism between the two languages is given by
\begin{equation}
  \label{eq:13}
  \Big(\sum_{\sigma_1,\ldots,\sigma_h, i_1,\ldots,
    i_h}a^{\sigma_1,\ldots,\sigma_h,\ j}_{i_1\cdots i_h} D_{\sigma_1}
  \varphi_1^{i_1}\cdots D_{\sigma_h}\varphi_h^{i_h}\Big)
  \longrightarrow
    \Big(\sum_{\sigma_1,\ldots,\sigma_h, i_1,\ldots,
      i_h}a^{\sigma_1,\ldots,\sigma_h,\ j}_{i_1\cdots i_h}
    % q_1{}^{i_1}_{\sigma_1} \cdots q_h{}^{i_h}_{\sigma_h}\Big)
        q^{i_1}_{\sigma_1} \cdots q^{i_h}_{\sigma_h}\Big)
\end{equation}
where $q^i_\sigma$ is the derivative of an odd dependent variable (and an odd
variable itself).

A superfunction in \cde must be declared as follows:
\begin{verbatim}
mk_superfun(sfname,num_arg,length_arg,length_target)
\end{verbatim}
where
\begin{itemize}
\item \texttt{sfname} is the name of the superfunction;
\item \texttt{num\_arg} is the degree of the superfunction \emph{eg} $h$ in
  \eqref{eq:13};
\item \texttt{length\_arg} is the list of lengths of the arguments: \emph{eg}
  the length of the single argument of $\Delta$ \eqref{eq:4} is $k$, and the
  corresponding list is \texttt{\{k\}}, while in \eqref{eq:7} one needs a list
  of $k$ items \texttt{\{k\_1,\dots,k\_h\}}, each corresponding to number of
  components of the vector functions to which the operator is applied;
\item \texttt{length\_target} is the numer of components of the image vector
  function.
\end{itemize}
The above parameters of the operator \texttt{opname} are stored in the property
list\footnote{The property list is a lisp concept, see \cite{inside} for
  details.} of the identifier \texttt{opname}. This means that if one would
like to know how many arguments has the operator \texttt{opname} the answer
will be the output of the command
\begin{verbatim}
get('cdnarg,cdiff_op);
\end{verbatim}
and the same for the other parameters.

The syntax for one component of the superfunction \texttt{sfname} is
\begin{verbatim}
  sfname(j)
\end{verbatim}

\cde is able to deal with \cdiffops in both formalisms, and provides
conversion utilities:
\begin{itemize}
\item \texttt{conv\_cdiff2superfun(cdop,superfun)}
\item \texttt{conv\_cdiff2superfun(superfun,cdop)}
\end{itemize}
where in the first case a $\mathcal{C}$-differential operator \texttt{cdop} is
converted into a vector superfunction \texttt{superfun} with the same
properties, and conversely.

\subsection{The Schouten bracket}
\label{sec:schouten-bracket}

We are interested in the operation of Schouten bracket between
\emph{variational multivectors} \cite{IVV}. These are differential operators
with $h$ arguments in $\varkappa$ with values in densities, and whose image is
defined up to total divergencies:
\begin{equation}
  \label{eq:16}
  \Delta\colon \varkappa\times\cdots\times \varkappa \to
  \{J^r(n,m) \to \lambda^nT^*\mathbb{R^n}\}/
  \bar{d}(\{J^r(n,m) \to \lambda^{n-1} T^*\mathbb{R^n}\})
\end{equation}
It is known \cite{getz,KKV} that the Schouten bracket between two variational
multivectors $A_1$, $A_2$ can be computed in terms of their corresponding
superfunction by the formula
\begin{equation}\label{eq:11}
  [A_1,A_2] = \Big[\fd{A_2}{u^j}\fd{A_1}{p_j} - (-1)^{(A_1 + 1)(A_2 + 1)}
 \fd{A_1}{u^j}\fd{A_2}{p_j}\Big]
\end{equation}
where $\fd{}{u^i}$, $\fd{}{p_j}$ are the variational derivatives and
the square brackets at the right-hand side should be understood as the
equivalence class up to total divergencies.

If the operators $A_1$, $A_2$ are compatible, \emph{ie} $[A_1,A_2]=0$, the
expression~\eqref{eq:11} must be a total derivative. This means that:
\begin{equation}
  \label{eq:14}
  [A_1,A_2] = 0 \quad\Leftrightarrow\quad
  \mathcal{E}\left(
\fd{A_2}{u^j}\fd{A_1}{p_j} - (-1)^{(A_1 + 1)(A_2 + 1)}
 \fd{A_1}{u^j}\fd{A_2}{p_j}
\right)=0.
\end{equation}

If $A_1$ is an $h$-vector and $A_2$ is a $k$-vector the formula~\eqref{eq:11}
produces a $(h+k-1)$-vector, or a \cdiffop with $h+k-1$ arguments. If we would
like to check that this multivector is indeed a total divergence, we should
apply the Euler operator, and check that it is zero. This procedure is
considerably simpler than the analogue formula with operators (see for example
\cite{KKV}). All this is computed by \cde:
\begin{verbatim}
schouten_bracket(biv1,biv2,tv12);
\end{verbatim}
where \texttt{biv1} and \texttt{biv2} are bivectors, or \cdiffops with $2$
arguments, and \texttt{tv12} is the result of the computation, which is a
three-vector (it is automatically declared to be a superfunction). Examples of
this computation are given in Section~\ref{sec:scho-brack-local}.

\section{Computing linearization and its adjoint}
\label{sec:linadj}

Currently, \cde supports linearization of a vector function, or a \cdiffop with
$0$ arguments. The computation is performed in odd coordinates.

Suppose that we would like to linearize the vector function that defines the
(dispersionless) Boussinesq equation \cite{KKV2}:
\begin{equation}
  \label{eq:1}
  \left\{
  \begin{array}{l}
  u_t-u_xv-uv_x-\sigma v_{xxx}=0\\
  v_t-u_x-vv_x=0
\end{array}
\right.
\end{equation}
where $\sigma$ is a constant. Then a jet space with independent variables
\texttt{x,t}, dependent variables \texttt{u,v} and odd variables \emph{in the
  same number as dependent variables} \texttt{p,q} must be created:
\begin{verbatim}
indep_var:={x,t}$
dep_var:={u,v}$
odd_var:={p,q}$
total_order:=8$
cde({indep_var,dep_var,odd_var,total_order},{})$
\end{verbatim}
The linearization of the above system and its adjoint are, respectively
\begin{displaymath}
  \ell_{\text{Bou}}=
  \begin{pmatrix}
    D_t-vD_x-v_x & -u_x-uD_x-\sigma D_{xxx}\\
    -D_x & D_t-v_x-vD_x
  \end{pmatrix},\
  \ell^*_{\text{Bou}}=
  \begin{pmatrix}
    -D_t+vD_x & D_x\\
    uD_x+\sigma D_{xxx} & -D_t+vD_x
  \end{pmatrix}
\end{displaymath}
Let us introduces the vector function whose zeros are the Boussinesq equation:
\begin{verbatim}
f_bou:={u_t - (u_x*v + u*v_x + sig*v_3x),v_t - (u_x + v*v_x)};
\end{verbatim}
The following command assigns to the identifier \texttt{lbou} the linearization
\cdiffop $\ell_{\text{Bou}}$ of the vector function \texttt{f\_bou}
\begin{verbatim}
ell_function(f_bou,lbou);
\end{verbatim}
moreover, a superfunction \texttt{lbou\_sf} is also defined as the vector
superfunction corresponding to $\ell_{\text{Bou}}$.
Indeed, the following sequence of commands:
\begin{verbatim}
2: lbou_sf(1);

 - p*v_x + p_t - p_x*v - q*u_x - q_3x*sig - q_x*u

3: lbou_sf(2);

 - p_x - q*v_x + q_t - q_x*v
\end{verbatim}
shows the vector superfunction corresponding to $\ell_{\text{Bou}}$. To compute
the value of the $(1,1)$ component of the matrix $\ell_{\text{Bou}}$ applied to
an argument \texttt{psi} do
\begin{verbatim}
lbou(1,1,psi);
\end{verbatim}
In order to check that the result is correct one could define the linearization
as a \cdiffop and then check that the corresponding superfunctions are the
same:
\begin{verbatim}
mk_cdiffop(lbou2,1,{2},2);
for all phi let lbou2(1,1,phi)=td(phi,t) - v*td(phi,x) - v_x*phi;
for all phi let lbou2(1,2,phi)= - u_x*phi - u*td(phi,x) - sig*td(phi,x,3);
for all phi let lbou2(2,1,phi)= - td(phi,x);
for all phi let lbou2(2,2,phi)=td(phi,t) - v*td(phi,x) - v_x*phi;

conv_cdiff2superfun(lbou2,lbou2_sf);
lbou2_sf(1) - lbou_sf(1);
lbou2_sf(2) - lbou_sf(2);
\end{verbatim}
the result of the two last commands must be zero.

The formal adjoint of \texttt{lbou} can be computed and assigned to the
identifier \texttt{lbou\_star} by the command
\begin{verbatim}
adjoint_cdiffop(lbou,lbou_star);
\end{verbatim}
Again, the associated vector superfunction \texttt{lbou\_star\_sf} is computed,
with values
\begin{verbatim}
4: lbou_star_sf(1);

 - p_t + p_x*v + q_x

5: lbou_star_sf(2);

p_3x*sig + p_x*u - q_t + q_x*v
\end{verbatim}
Again, the above operator can be checked for correctness.

Once the linearization and its ajdoint are computed, in order to do
computations with symmetries and conservation laws such operator must be
restricted to the corresponding equation. This can be achieved with the
following steps:
\begin{enumerate}
\item \label{first} compute linearization of a PDE of the form $F=0$ and its
  adjoint, and save them in the form of a vector superfunction;
\item start a new computation with the given \emph{even} PDE as a constraint on
  the (even) jet space;
\item load the superfunctions of item \ref{first};
\item restrict them to the even PDE.
\end{enumerate}
Only the last step needs to be explained. If we are considering, \emph{eg} the
Boussinesq equation, then $u_t$ and its differential consequences (\emph{ie}
the principal derivatives) are not automatically expanded to the right-hand
side of the equation and its differential consequences. At the moment this step
is not fully automatic. More precisely, only principal derivatives which appear
as coefficients in total derivatives can be replaced by their expression.  The
lists of such derivatives with the corresponding expressions are
\texttt{repprincparam\_der} and \texttt{repprincparam\_odd} (see
Section~\ref{sec:diff-equat-even}). They are in the format of \reduce's
replacement list and can be used in let-rules. If the linearization or its
adjoint happen to depend on another principal derivative this must be computed
separately. A forthcoming release of \reduce will automatize this procedure.

However, note that for evolutionary equations this step is trivial, as the
restriction of linearization and its adjoint on the given PDE will only affect
total derivatives which are restricted by \cde to the PDE.

\section{Higher symmetries}\label{sec:higher-symmetries}
\label{sec:higher-symmetries-1}

In this section we show the computation of (some) higher \cite{Many} (or
generalized, \cite{Olv}) symmetries of Burgers'equation $B=u_t-u_{xx}+2uu_x=0$.

We provide two ways to solve the equations for higher symmetries. The first
possibility is to use dimensional analysis. The idea is that one can use the
scale symmetries of Burgers'equation to assign ``gradings'' to each variable
appearing in the equation (in other words, one can use dimensional
analisys). As a consequence, one could try different ansatz for symmetries with
polynomial generating functions. For example, it is possible to require that
they are sum of monomials of given degrees. This ansatz yields a simplification
of the equations for symmetries, because it is possible to solve them in a
``graded'' way, \emph{i.e.}, it is possible to split them into several
equations made by the homogeneous components of the equation for symmetries
with respect to gradings.

In particular, Burgers'equation translates into the following dimensional
equation:
\begin{displaymath}
  [u_t]=[u_{xx}],\quad [u_{xx}]=[2uu_x].
\end{displaymath}
By the rules $[u_z]=[u]-[z]$ and $[uv]=[u]+[v]$, and choosing $[x]=-1$, we have
$[u]=1$ and $[t]=-2$. This will be used to generate the list of homogeneous
monomials of given grading to be used in the ansatz about the structure of the
generating function of the symmetries.

The file for the above computation is
\texttt{bur\_hsy1.red} and the results of the computation are in
\texttt{results/bur\_hsy1\_res.red}.

Another possibility to solve the equation for higher symmetries is to use a
PDE solver that is especially devoted to overdetermined systems, which is the
distinguishing feature of systems coming from the symmetry analysis of PDEs.
This approach is described below. The file for the above computation is
\texttt{bur\_hsy2.red} and the results of the computation are in
\texttt{results/bur\_hsy2\_res.red}.


\subsection{Setting up the jet space and the differential equation.}
\label{sec:setting-up-jet}

After loading \cde:
\begin{verbatim}
indep_var:={x,t}$
dep_var:={u}$
deg_indep_var:={-1,-2}$
deg_dep_var:={1}$
total_order:=10$
\end{verbatim}
Here the new lists are scale degrees:
\begin{itemize}
\item \texttt{deg\_indep\_var} is the list of scale degrees of the independent
  variables;
\item \texttt{deg\_dep\_var} is the list of scale degrees of the dependent
  variables;
\end{itemize}

We now give the equation and call \cde:
\begin{verbatim}
principal_der:={u_t}$
de:={u_2x+2*u*u_x}$
cde({indep_var,dep_var,{},total_order},
   {principal_der,de,{},{}})$
\end{verbatim}

\subsection{Solving the problem via dimensional analysis.}
\label{sec:solving-problem-via}

Higher symmetries of the given equation are functions \texttt{sym} depending on
parametric coordinates up to some jet space order. We assume that they are
graded polynomials of all parametric derivatives. In practice, we generate a
linear combination of graded monomials with arbitrary coefficients, then we
plug it in the equation of the problem and find conditions on the coefficients
that fulfill the equation.  To construct a good ansatz, it is required to make
several attempts with different gradings, possibly including independent
variables, etc.. For this reason, ansatz-constructing functions are especially
verbose.  In order to use such functions they must be initialized with the
following command:
\begin{verbatim}
cde_grading(deg_indep_var,deg_dep_var,{})$
\end{verbatim}
Note the empty list at the end; it playe a role only for computations involving
odd variables.

We need one operator \texttt{equ} whose components will be the equation of
higher symmetries and its consequences. Moreover, we need an operator
\texttt{c} which will play the role of a vector of constants, indexed by a
counter \texttt{ctel}:
\begin{verbatim}
ctel:=0;
operator c,equ;
\end{verbatim}
We prepare a list of variables ordered by scale degree:
\begin{verbatim}
l_grad_var:=der_deg_ordering(0,all_parametric_der)$
\end{verbatim}
The function \texttt{der\_deg\_ordering} is defined in \texttt{cde.red}. It
produces the given list using the list \texttt{all\_parametric\_der} of all
parametric derivatives of the given equation up to the order
\texttt{total\_order}. The first two parameters can assume the values $0$ or $1$
and say that we are considering even variables and that the variables are of
parametric type.

Then, due to the fact that \emph{all parametric
  variables have positive scale degree} then we prepare the list
\texttt{ansatz} of all graded monomials of scale degree from $0$ to $5$
\begin{verbatim}
gradmon:=graded_mon(1,5,l_grad_var)$
gradmon:={1} . gradmon$
ansatz:=for each el in gradmon join el$
\end{verbatim}
More precisely, the command \texttt{graded\_mon} produces a list of monomials of
degrees from \texttt{i} to \texttt{j}, formed from the list of graded variables
\texttt{l\_grad\_var}; the second command adds the zero-degree monomial; and the
last command produces a single list of all monomials.

Finally, we assume that the higher symmetry is a graded polynomial obtained
from the above monomials (so, it is independent of $x$ and $t$!)
\begin{verbatim}
sym:=(for each el in ansatz sum (c(ctel:=ctel+1)*el))$
\end{verbatim}
Next, we define the equation $\ell_B(\mathtt{sym})=0$. Here, $\ell_B$ stands
for the linearization (Section~\ref{sec:linadj}). A function
\texttt{sym} that fulfills the above equation, on account of $B=0$, is an higher
symmetry.

We \textbf{cannot} define the linearization as a \cdiffop in this way:
\begin{verbatim}
bur:={u_t - (2*u*u_x+u_2x)};
ell_function(bur,lbur);
\end{verbatim}
as the linearization is performed with respect to parametric derivatives only!
This means that the linearization has to be computed beforehand in a free jet
space, then it may be used here.

So, the right way to go is
\begin{verbatim}
mk_cdiffop(lbur,1,{1},1);
for all phi let lbur(1,1,phi)=td(phi,t)-td(phi,x,2)-2*u*td(phi,x)-2*u_x*phi;
\end{verbatim}
Note that for evolutionary equations the restriction of the linearization to
the equation is equivalent to just restricting total
derivatives, which is automatic in \cde.

The equation becomes
\begin{verbatim}
equ 1:=lbur(1,1,sym);
\end{verbatim}
At this point we initialize the equation solver. This is a part of the \cdiff
package called \texttt{integrator.red} (see the original documentation inside
the folder \texttt{packages/cdiff} in \reduce's source code). In our case the
above package will solve a large sparse linear system of algebraic equations on
the coefficients of \texttt{sym}.

The list of variables, to be passed to the equation solver:
\begin{verbatim}
vars:=append(indep_var,all_parametric_der);
\end{verbatim}
The number of initial equation(s):
\begin{verbatim}
tel:=1;
\end{verbatim}
Next command initializes the equation solver.  It passes
\begin{itemize}
  \item the equation vector \texttt{equ} togeher with its length \texttt{tel}
    (\emph{i.e.}, the total number of equations);
  \item the list of variables with respect to which the system \emph{must not}
    split the equations, \emph{i.e.}, variables with respect to which the
    unknowns are not polynomial. In this case this list is just $\{\}$;
  \item the constants'vector \texttt{c}, its length \texttt{ctel}, and the
    number of negative indexes if any; just $\texttt{0}$ in our example;
  \item the vector of free functions \texttt{f} that may appear in
    computations. Note that in \texttt{$\{$f,0,0 $\}$} the second $\texttt{0}$
    stands for the length of the vector of free functions. In this example
    there are no free functions, but the command needs the presence of at least
    a dummy argument, \texttt{f} in this case. There is also a last zero which
    is the negative length of the vector $f$, just as for constants.
  \end{itemize}
\begin{verbatim}
initialize_equations(equ,tel,{},{c,ctel,0},{f,0,0});
\end{verbatim}
Run the procedure \texttt{splitvars\_opequ} on the first component of
\texttt{equ} in order to obtain equations on coefficiens of each monomial.
\begin{verbatim}
tel:=splitvars_opequ(equ,1,1,vars);
\end{verbatim}
Note that \texttt{splitvars\_opequ} needs to know the indices of the first and
the last equation in \texttt{equ}, and here we have only one equation as
\texttt{equ(1)}. The output \texttt{tel} is the final number of splitted
equations, starting just after the initial equation \texttt{equ(1)}.

Next command tells the solver the total number of equations obtained
after running \texttt{splitvars}.
\begin{verbatim}
put_equations_used tel;
\end{verbatim}
This command solves the equations for the coefficients.
Note that we have to skip the initial equations!
\begin{verbatim}
for i:=2:tel do integrate_equation i;
\end{verbatim}

The output is written in the result file by the commands
\begin{verbatim}
off echo$
off nat$
out <<resname>>;
sym:=sym;
write ";end;";
shut <<resname>>;
on nat$
on echo$
\end{verbatim}
The command \texttt{off nat} turns off writing in natural notation; results in
this form are better only for visualization, not for writing or for input into
another computation. The command \texttt{<<resname>>} forces the evaluation of
the variable \texttt{resname} to its string value. The commands \texttt{out}
and \texttt{shut} are for file opening and closing. The command
\texttt{sym:=sym} is evaluated only on the right-hand side.

One more example file is available; it concerns higher symmetries of the KdV
equation. In order to deal with symmetries explicitely depending on $x$ and
$t$ it is possible to use \reduce and \cde commands in order to have
\texttt{sym = x*}(something of degree 3)\texttt{ + t*}(something of degree  5)
+ (something of degree 2); this yields scale symmetries.
Or we could use \texttt{sym = x*}(something of degree 1)\texttt{ +
  t*}(something of degree 3) + (something of degree 0);
this yields Galilean boosts.

\subsection{Solving the problem using CRACK}

\crack is a PDE solver which is devoted mostly to the solution of
overdetermined PDE systems \cite{wbde,crack}. Several mathematical problems
have been solved by the help of \crack, like finding symmetries
\cite{wolfsy,wolfsy0} and conservation laws \cite{wolfcl}. The aim of \cde is
to provide a tool for computations with total derivatives, but it can be used
to compute symmetries too. In this subsection we show how to interface \cde
with \crack in order to find higher (or generalized) symmetries for the
Burgers'equation. To do that, after loading \cde and introducing the equation,
we define the linearization of the equation \texttt{lbur}.

We introduce the new unknown function `\texttt{ansatz}'. We assume that the
function depends on parametric variables of order not higher than $3$.  The
variables are selected by the function \texttt{selectvars} of \cde as follows:
\begin{verbatim}
even_vars:=for i:=0:3 join selectvars(0,i,dep_var,all_parametric_der)$
\end{verbatim}
In the arguments of \texttt{selectvars}, \texttt{0} means that we want even
variables, \texttt{i} stands for the order of variables, \texttt{dep\_var}
stands for the dependent variables to be selected by the command (here we use
all dependent variables), \texttt{all\_parametric\_der} is the set of variables
where the function will extract the variables with the required properties.
In the current example we wish to get all higher symmetries depending on
parametric variables of order not higher than $3$.

The dependency of \texttt{ansatz} from the variables is given with the standard
\reduce command \texttt{depend}:
\begin{verbatim}
for each el in even_vars do depend(ansatz,el)$
\end{verbatim}
The equation to be solved is the equation \texttt{lbur(ansatz)=0}, hence we
give the command
\begin{verbatim}
total_eq:=lbur(1,1,ansatz)$
\end{verbatim}
The above command will issue an error if the list \texttt{\{total\_eq\}}
depends on the flag variable \texttt{letop}. In this case the computation has
to be redone within a jet space of higher order.

The equation \texttt{ell\_b(ansatz)=0} is polynomial with respect to the
variables of order higher than those appearing in \texttt{ansatz}. For this
reason, its coefficients can be put to zero independently. This is the reason
why the PDEs that determine symmetries are overdetermined. To tell this to
\crack, we issue the command
\begin{verbatim}
split_vars:=diffset(all_parametric_der,even_vars)$
\end{verbatim}
The list \texttt{split\_vars} contains variables which are in the current
\cde jet space but \emph{not} in \texttt{even\_vars}.

Then, we load the package \crack and get results.
\begin{verbatim}
load_package crack;
crack_results:=crack(total_eq,{},{ansatz},split_vars);
\end{verbatim}
The results are in the variable \texttt{crack\_results}:
\begin{verbatim}
{{{},
{ansatz=(2*c_12*u_x + 2*c_13*u*u_x + c_13*u_2x + 6*c_8*u**2*u_x
 + 6*c_8*u*u_2x + 2*c_8*u_3x + 6*c_8*u_x**2)/2},
{c_8,c_13,c_12},
{}}}$
\end{verbatim}
So, we have three symmetries; of course the generalized symmetry corresponds to
\texttt{c\_8}. Remember to check \emph{always} the output of CRACK to see if
any of the symbols \texttt{c\_n} is indeed a free function depending on some of
the variables, and not just a constant.


\section{Local conservation laws}
\label{sec:local-cons-laws}

In this section we will find (some) local conservation laws for the KdV
equation $F=u_t-u_{xxx}+uu_x=0$. Concretely, we have to find non-trivial
$1$-forms $f=f_xdx+f_tdt$ on $F=0$ such that $\bar d f=0$ on
$F=0$. ``Triviality'' of conservation laws is a delicate matter, for which we
invite the reader to have a look in \cite{Many}.

The files containing this example are \texttt{kdv\_lcl1,kdv\_lcl2}
and the corresponding results and debug files.

We suppose that the conservation law has the form $\omega=f_x dx+f_t dt$.
Using the same \texttt{ansatz} as in the previous example we assume
\begin{verbatim}
fx:=(for each el in ansatz sum (c(ctel:=ctel+1)*el))$
ft:=(for each el in ansatz sum (c(ctel:=ctel+1)*el))$
\end{verbatim}
Next we define the equation $\bar d(\omega)=0$, where $\bar d$ is the total
exterior derivative restricted to the equation.
\begin{verbatim}
equ 1:=td(fx,t)-td(ft,x)$
\end{verbatim}

After solving the equation as in the above example we get
\begin{verbatim}
fx := c(3)*u_x + c(2)*u + c(1)$
ft := (2*c(8) + 2*c(3)*u*u_x + 2*c(3)*u_3x + c(2)*u**2 +
2*c(2)*u_2x)/2$
\end{verbatim}
Unfortunately it is clear that the conservation law corresponding to
\texttt{c(3)} is trivial, because it is just the KdV equation. Here this fact
is evident; how to get rid of less evident trivialities by an `automatic'
mechanism? We considered this problem in the file \texttt{kdv\_lcl2},
where we solved the equation
\begin{verbatim}
equ 1:=fx-td(f0,x);
equ 2:=ft-td(f0,t);
\end{verbatim}
after having loaded the values \texttt{fx} and \texttt{ft} found by the
previous program. In order to do that we have to introduce two new counters:
\begin{verbatim}
operator cc,equ;
cctel:=0;
\end{verbatim}
We make the following ansatz on \texttt{f0}:
\begin{verbatim}
f0:=(for each el in ansatz sum (cc(cctel:=cctel+1)*el))$
\end{verbatim}
After solving the system, issuing the commands
\begin{verbatim}
fxnontriv := fx-td(f0,x);
ftnontriv := ft-td(f0,t);
\end{verbatim}
we obtain
\begin{verbatim}
fxnontriv := c(2)*u + c(1)$
ftnontriv := (2*c(8) + c(2)*u**2 + 2*c(2)*u_2x)/2$
\end{verbatim}
This mechanism can be easily generalized to situations in which the
conservation laws which are found by the program are difficult to treat by pen
and paper. However, we will present another approach to the computation of
conservation laws in subsection~\ref{sec:plebanski-equation}.

\section{Local Hamiltonian operators}
\label{sec:local-hamilt-oper}

In this section we will show how to compute local Hamiltonian operators for
Korteweg--de Vries, Boussinesq and Kadomtsev--Petviashvili equations. It is
interesting to note that we will adopt the same computational scheme for all
equations, even if the latter is not in evolutionary form and it has more than
two independent variables. This comes from a new mathematical theory which
started in \cite{KKV} for evolution equations and was later extended to general
differential equations in \cite{KerstenKrasilshchikVerbovetskyVitolo:HSGP}.

\subsection{Korteweg--de Vries equation}
\label{sec:korteweg-de-vries}

Here we will find local Hamiltonian operators for the KdV equation
$u_t=u_{xxx}+uu_x$. A necessary condition for an operator to be Hamiltonian is
that it sends generating functions (or characteristics, according with
\cite{Olv}) of conservation laws to higher (or generalized) symmetries.
As it is proved in \cite{KKV}, this amounts at solving $\bar
\ell_{KdV}(\mathtt{phi})=0$ over the equation
\begin{displaymath}
  \left\{\begin{array}{l}
    u_t=u_{xxx}+uu_x\\
    p_t=p_{xxx}+up_x
  \end{array}\right.
\end{displaymath}
or, in geometric terminology, find the shadows of symmetries on the
$\ell^*$-covering of the KdV equation, with the further condition that the
shadows must be linear in the $p$-variables. Note that the second equation (in
odd variables!) is just the adjoint of the linearization of the KdV equation
applied to an odd variable.

The file containing this example is \texttt{kdv\_lho1}.

We stress that the linearization $\bar \ell_{KdV}(\mathtt{phi})=0$ is the
equation
\begin{verbatim}
td(phi,t)-u*td(phi,x)-u_x*phi-td(phi,x,3)=0
\end{verbatim}
but the total derivatives are lifted to the $\ell^*$ covering, hence they
contain also derivatives with respect to $p$'s. We can define a linearization
operator \texttt{lkdv} as usual.

In order to produce an ansatz which is a superfunction of one odd variable (or
a linear function in odd variables) we produce two lists: the list
\texttt{l\_grad\_var} of all even variables collected by their gradings and a
similar list \texttt{l\_grad\_odd} for odd variables:
\begin{verbatim}
l_grad_var:=der_deg_ordering(0,all_parametric_der)$
l_grad_odd:={1} . der_deg_ordering(1,all_parametric_odd)$
gradmon:=graded_mon(1,10,l_grad_var)$
gradmon:={1} . gradmon$
\end{verbatim}
We need a list of graded monomials which are linear in odd variables. The
function \texttt{mkalllinodd} produces all monomials which are linear with
respect to the variables from \texttt{graadlijst\_odd}, have (monomial)
coefficients from the variables in \texttt{graadlijst}, and have total scale
degrees from $1$ to $6$. Such monomials are then converted to the internal
representation of odd variables.
\begin{verbatim}
linodd:=mkalllinodd(gradmon,l_grad_odd,1,6)$
\end{verbatim}
Note that all odd variables have positive scale degrees thanks to our initial
choice \texttt{deg\_odd\_var:={1};}.
Finally, the ansatz for local Hamiltonian operators:
\begin{verbatim}
sym:=(for each el in linext sum (c(ctel:=ctel+1)*el))$
\end{verbatim}
After having set
\begin{verbatim}
equ 1:=lkdv(1,1,sym);
\end{verbatim}
and having initialized the equation solver as before, we do \texttt{splitext}
\begin{verbatim}
tel:=splitext_opequ(equ,1,1);
\end{verbatim}
in order to split the polynomial equation with respect to the \texttt{ext}
variables, then \texttt{splitvars}
\begin{verbatim}
tel2:=splitvars_opequ(equ,2,tel,vars);
\end{verbatim}
in order to split the resulting polynomial equation in a list of equations on
the coefficients of all monomials.

Now we are ready to solve all equations:
\begin{verbatim}
put_equations_used tel;
for i:=2:tel do integrate_equation i;
end;
\end{verbatim}
Note that we want \emph{all} equations to be solved!

The results are the two well-known Hamiltonian operators for the KdV. 
After integration the function \texttt{sym} becomes
\begin{verbatim}
sym := (c(5)*p*u_x + 2*c(5)*p_x*u + 3*c(5)*p_3x + 3*c(2)*p_x)/3$
\end{verbatim}
Of course, the results correspond to the operators
\begin{gather*}
  p_x \to D_x,\\
  \frac{1}{3}(3p_{3x} + 2up_x + u_xp) \to \frac{1}{3}(3D_{xxx} + 2uD_{x} + u_x)
\end{gather*}
Note that each operator is multiplied by one arbitrary real
constant, \texttt{c(5)} and \texttt{c(2)}.

The same problem can be approached using CRACK, as follows (file
\texttt{kdv\_lho2.red}). An ansatz is constructed by the following
instructions:
\begin{verbatim}
even_vars:=for i:=0:3 join selectvars(0,i,dep_var,all_parametric_der)$
odd_vars:=for i:=0:3 join selectvars(1,i,odd_var,all_parametric_odd)$
ext_vars:=replace_oddext(odd_vars)$

ctemp:=0$
ansatz:=for each el in ext_vars sum mkid(s,ctemp:=ctemp+1)*el$
\end{verbatim}
Note that we have
\begin{verbatim}
ansatz := p*s1 + p_2x*s3 + p_3x*s4 + p_x*s2$
\end{verbatim}
Indeed, we are looking for a third-order operator whose coefficients depend on
variables of order not higher than $3$. This last property has to be introduced
by
\begin{verbatim}
unk:=for i:=1:ctemp collect mkid(s,i)$
for each ell in unk do
 for each el in even_vars do depend ell,el$
\end{verbatim}
Then, we introduce the linearization (lifted on the cotangent covering)
\begin{verbatim}
operator ell_f$
for all sym let ell_f(sym)=
   td(sym,t) - u*td(sym,x) - u_x*sym - td(sym,x,3)$
\end{verbatim}
and the equation to be solved, together with the usual test that checks for the
nedd to enlarge the jet space:
\begin{verbatim}
total_eq:=ell_f(ansatz)$
\end{verbatim}
Finally, we split the above equation by collecting all coefficients of odd
variables:
\begin{verbatim}
system_eq:=splitext_list({total_eq})$
\end{verbatim}
and we feed CRACK with the equations that consist in asking to the above
coefficients to be zero:
\begin{verbatim}
load_package crack;
crack_results:=crack(system_eq,{},unk,
   diffset(all_parametric_der,even_vars));
\end{verbatim}
The results are the same as in the previous section:
\begin{verbatim}
crack_results := {{{},
{s4=(3*c_17)/2,s3=0,s2=c_16 + c_17*u,s1=(c_17*u_x)/2},
{c_17,c_16},
{}}}$
\end{verbatim}


\subsection{Boussinesq equation}
\label{sec:comp-syst-pdes}

There is no conceptual difference when computing for systems of PDEs with
respect to the previous computations for scalar equations. We will look for
Hamiltonian structures for the dispersionless Boussinesq equation \eqref{eq:1}.

We will proceed by dimensional analysis. Gradings can be taken as
\begin{displaymath}
  [t]=-2,\quad [x]=-1,\quad [v]=1,\quad [u]=2,\quad [p]=1,\quad [q]=2
\end{displaymath}
where $p$, $q$ are the two odd coordinates. We have the
$\ell^*_{\text{Bou}}$ covering equation
\begin{displaymath}
  \label{eq:12}
  \left\{
  \begin{array}{l}
    -p_t+vp_x+q_x=0\\
    up_x+\sigma p_{xxx}-q_t+vq_x=0\\
  u_t-u_xv-uv_x-\sigma v_{xxx}=0\\
  v_t-u_x-vv_x=0
\end{array}
\right.
\end{displaymath}
We have to find Hamiltonian operators as shadows of symmetries on the above
covering.  At the level of source file (\texttt{bou\_lho1}) the input
data is:
\begin{verbatim}
indep_var:={x,t}$
dep_var:={u,v}$
odd_var:={p,q}$
deg_indep_var:={-1,-2}$
deg_dep_var:={2,1}$
deg_odd_var:={1,2}$
total_order:=8$
principal_der:={u_t,v_t}$
de:={u_x*v+u*v_x+sig*v_3x,u_x+v*v_x}$
principal_odd:={p_t,q_t}$
de_odd:={v*p_x+q_x,u*p_x+sig*p_3x+v*q_x}$
\end{verbatim}
The ansatz for the components of the Hamiltonian operator, of scale degree
between $1$ and $6$, is
\begin{verbatim}
linodd:=mkalllinodd(gradmon,l_grad_odd,1,6)$
phi1:=(for each el in linodd sum (c(ctel:=ctel+1)*el))$
phi2:=(for each el in linodd sum (c(ctel:=ctel+1)*el))$
\end{verbatim}
and the equation for shadows of symmetries is (\texttt{lbou2} is taken from
Section~\ref{sec:linadj})
\begin{verbatim}
equ 1:=lbou2(1,1,phi1) + lbou2(1,2,phi2);

equ 2:=lbou2(2,1,phi1) + lbou2(2,2,phi2);
\end{verbatim}
After the usual procedures for decomposing polynomials we obtain three local
Hamiltonian operators:
\begin{verbatim}
phi1_odd := (2*c(31)*p*sig*v_3x + 2*c(31)*p*u*v_x + 2*c(31)*p*u_x*v + 6*c(31)*
p_2x*sig*v_x + 4*c(31)*p_3x*sig*v + 6*c(31)*p_x*sig*v_2x + 4*c(31)*p_x*u*v + 2*c
(31)*q*u_x + 4*c(31)*q_3x*sig + 4*c(31)*q_x*u + c(31)*q_x*v**2 + 2*c(16)*p*u_x +
 4*c(16)*p_3x*sig + 4*c(16)*p_x*u + 2*c(16)*q_x*v + 2*c(10)*q_x)/2$

phi2_odd := (2*c(31)*p*u_x + 2*c(31)*p*v*v_x + 4*c(31)*p_3x*sig + 4*c(31)*p_x*u 
+ c(31)*p_x*v**2 + 2*c(31)*q*v_x + 4*c(31)*q_x*v + 2*c(16)*p*v_x + 2*c(16)*p_x*v
 + 4*c(16)*q_x + 2*c(10)*p_x)/2$
\end{verbatim}
There is a whole hierarchy of nonlocal Hamiltonian operators~\cite{KKV}.


\subsection{Kadomtsev--Petviashvili equation}
\label{sec:mult-case}

There is no conceptual difference in symbolic computations of Hamiltonian
operators for PDEs in $2$ independent variables and in more than $2$
independent variables, regardless of the fact that the equation at hand is
written in evolutionary form. As a model example, we consider the KP equation
\begin{equation}
  \label{eq:3}
  u_{yy}=u_{tx}-u_x^2-uu_{xx}-\frac{1}{12}u_{xxxx}.
\end{equation}
Proceeding as in the above examples we input the following data:
\begin{verbatim}
indep_var:={t,x,y}$
dep_var:={u}$
odd_var:={p}$
deg_indep_var:={-3,-2,-1}$
deg_dep_var:={2}$
deg_odd_var:={1}$
total_order:=6$
principal_der:={u_2y}$
de:={u_tx-u_x**2-u*u_2x-(1/12)*u_4x}$
principal_odd:={p_2y}$
de_odd:={p_tx-u*p_2x-(1/12)*p_4x}$
\end{verbatim}
and look for Hamiltonian operators of scale degree between $1$ and $5$:
\begin{verbatim}
linodd:=mkalllinodd(gradmon,l_grad_odd,1,5)$
phi:=(for each el in linodd sum (c(ctel:=ctel+1)*el))$
\end{verbatim}
After solving the equation for shadows of symmetries in the cotangent covering
\begin{verbatim}
equ 1:=td(phi,y,2) - td(phi,x,t) + 2*u_x*td(phi,x)
 + u_2x*phi + u*td(phi,x,2) + (1/12)*td(phi,x,4);
\end{verbatim}
we get the only local Hamiltonian operator
\begin{verbatim}
phi := c(13)*p_2x$
\end{verbatim}
As far as we know there are no further local Hamiltonian operators.

\textbf{Remark}: the above Hamiltonian operator is already known in an
evolutionary presentation of the KP equation \cite{Kupershmidt:KP}. Our
mathematical theory of Hamiltonian operators for general differential equations
\cite{KerstenKrasilshchikVerbovetskyVitolo:HSGP} allows us to formulate and
solve the problem for any presentation of the KP equation. Change of coordinate
formulae could also be provided.


\section{Examples of Schouten bracket of local Hamiltonian
  operators}
\label{sec:scho-brack-local}

Let $F=0$ be a system of PDEs. Here $F\in P$, where $P$ is the module (in the
algebraic sense) of vector functions $P=\{J^r(n,m) \to \mathbb{R}^k\}$.

The Hamiltonian operators which have been computed in the previous Section are
differential operators sending generating functions of conservation laws into
generating functions of symmetries for the above system of PDEs:
\begin{equation}
  \label{eq:15}
  H\colon \hat P \to \varkappa
\end{equation}
\begin{itemize}
  \item $\hat P=\{J^r(n,m) \to (\mathbb{R}^k)^*\otimes\wedge^n
    T^*\mathbb{R}^n\}$ is the space of covector-valued densities,
  \item $\varkappa=\{J^r(n,m) \to \mathbb{R}^m\}$ is the space of generalized
    vector fields on jets; generating functions of higher symmetries of the
    system of PDEs are elements of this space.
  \end{itemize}
As the operators are mainly used to define a bracket operation and a Lie
algebra structure on conservation laws, two properties are required:
skew-adjointness $H^* = -H$ (corresponding with skew-symmetry of the bracket)
and $[H,H]=0$ (corresponding with the Jacobi property of the bracket).

In order to compute the two properties we proceed as follows.  Skew-adjointness
is checked by computing the adjoint and verifying that the sum with the initial
operator is zero.

In the case of evolutionary equations, $P=\varkappa$, and Hamiltonian
operators~\eqref{eq:15} can also be interpreted as \emph{variational bivectors,
  ie}
\begin{equation}
  \label{eq:17}
  \hat H\colon \hat\varkappa\times\hat\varkappa \to \wedge^n T^*\mathbb{R}^n
\end{equation}
where the correspondence is given by
\begin{equation}
  \label{eq:18}
  H(\psi) = (a^{ij\sigma}D_\sigma\psi_j)
  \quad \to \quad
    \hat H(\psi_1,\psi_2) = (a^{ij\sigma}D_\sigma\psi_{1\ j}\psi_{2\ i})
\end{equation}

In terms of the corresponding superfunctions:
\begin{displaymath}
  H = a^{ik\,\sigma} p_{k\,\sigma} \quad \to \quad
  \hat H = a^{ik\,\sigma} p_{k\,\sigma}p_i.
\end{displaymath}
Note that the product $p_{k\,\sigma}p_i$ is anticommutative since $p$'s are odd
variables.

After that a \cdiffop of the type of $H$ has been converted into a bivector it
is possible to apply the formulae \eqref{eq:11} and~\eqref{eq:14} in order to
compute the Schouten bracket. This is what we will see in next section.


\subsection{Bi-Hamiltonian structure of the KdV equation}
\label{sec:bi-hamilt-struct}

We can do the above computations using KdV equation as a test case (see the
file \texttt{kdv\_lho3.red}).

Let us load the above operators:
\begin{verbatim}
operator ham1;
for all psi1 let ham1(psi1)=td(psi1,x);
operator ham2;
for all psi2 let ham2(psi2)=(1/3)*u_x*psi2 + td(psi2,x,3)
 + (2/3)*u*td(psi2,x);
\end{verbatim}
We may convert the two operators into the corresponding superfunctions
\begin{verbatim}
conv_cdiff2superfun(ham1,sym1);
conv_cdiff2superfun(ham2,sym2);
\end{verbatim}
The result of the conversion is
\begin{verbatim}
sym1(1) := {p_x};
sym2(2) := {(1/3)*p*u_x + p_3x + (2/3)*p_x*u};
\end{verbatim}
Skew-adjointness is checked at once:
\begin{verbatim}
adjoint_cdiffop(ham1,ham1_star);
adjoint_cdiffop(ham2,ham2_star);
ham1_star_sf(1)+sym1(1);
ham2_star_sf(1)+sym2(1);
\end{verbatim}
and the result of the last two commands is zero.

Then we shall convert the two superfunctions into bivectors:
\begin{verbatim}
conv_genfun2biv(sym1_odd,biv1);
conv_genfun2biv(sym2_odd,biv2);
\end{verbatim}
The output is:
\begin{verbatim}
biv1(1) :=  - ext(p,p_x);
biv2(1) := - (1/3)*( - 3*ext(p,p_3x) - 2*ext(p,p_x)*u);
\end{verbatim}
Finally, the three Schouten brackets $[\hat H_i,\hat H_j]$ are computed, with
$i,j=1,2$:
\begin{verbatim}
schouten_bracket(biv1,biv1,sb11);
schouten_bracket(biv1,biv2,sb12);
schouten_bracket(biv2,biv2,sb22);
\end{verbatim}
the result are well-known lists of zeros.

\subsection{Bi-Hamiltonian structure of the WDVV equation}
\label{sec:bi-hamilt-struct-1}

This subsection refers to the the example file \texttt{wdvv\_biham1.red}.
The simplest nontrivial case of the WDVV equations is the third-order
Monge--Amp\`ere equation, $f_{ttt} = f_{xxt}^2 - f_{xxx}f_{xtt}$
\cite{Dub}. This PDE can be transformed into hydrodynamic form,
\begin{equation*}
  % \label{eq:8}
  a_t=b_x,\quad b_t=c_x,\quad c_t=(b^2-ac)_x,
\end{equation*}
via the change of variables $a=f_{xxx}$, $b=f_{xxt}$, $c=f_{xtt}$. This system
possesses two Hamiltonian formulations \cite{FN}:
\begin{equation*}
  \begin{pmatrix}
    a \\ b \\ c
  \end{pmatrix}_t =A_i
  \begin{pmatrix}
    \fd{H_i}{a}\\ \fd{H_i}{b} \\ \fd{H_i}{c}
  \end{pmatrix},\quad i=1,2
\end{equation*}
with the homogeneous first-order Hamiltonian operator
\begin{displaymath}
\hat{A}_{1}=%
\begin{pmatrix}
-\frac{3}{2}D _{x}^{{}} & \frac{1}{2}D _{x}^{{}}a & D
_{x}^{{}}b \\ 
\frac{1}{2}aD _{x}^{{}} & \frac{1}{2}(D _{x}^{{}}b+bD
_{x}^{{}}) & \frac{3}{2}cD _{x}^{{}}+c_{x} \\ 
bD _{x}^{{}} & \frac{3}{2}D _{x}^{{}}c-c_{x} & 
(b^{2}-ac)D _{x}^{{}}+D _{x}^{{}}(b^{2}-ac)%
\end{pmatrix}
\end{displaymath}%
with the Hamiltonian $H_1 = \int c \, dx$,
and the homogeneous third-order Hamiltonian operator
$$
  A_2= \ddx{}\left(
    \begin{array}{ccc}
      0 & 0 & \displaystyle\ddx{} \\
      0 & \displaystyle\ddx{} & -\displaystyle\ddx{}a \\
      \displaystyle\ddx{} & -a\displaystyle\ddx{} &
      \displaystyle\ddx{}b + b\ddx{} + a \ddx{} a
    \end{array}\right)
  \ddx{},
$$
with the nonlocal Hamiltonian
\begin{displaymath}
  H_2=-\int\left(  \frac{1}{2}a\left({\ddx{}}^{-1}b\right)^2 + {\ddx{}}^{-1}b
  {\ddx{}}^{-1}c\right)dx.
\end{displaymath}
Both operators are of Dubrovin--Novikov type \cite{DN,DN2}. This means that the
operators are homogeneous with respect to the grading $|D_x|=1$. It follows
that the operators are form-invariant under point transformations of the
dependent variables, $u^i=u^i(\tilde u^j)$. Here and in what follows we will
use the letters $u^i$ to denote the dependent variables $(a,b,c)$. Under such
transformations, the coefficients of the operators transform as
differential-geometric objects.

The operator $A_1$ has the general structure
\begin{displaymath}
  A_1 = g_1^{ij}\ddx{} + \Gamma^{ij}_ku^k_x
\end{displaymath}
where the covariant metric $g_{1\,ij}$ is flat, $\Gamma^{ij}_k =
g_1^{is}\Gamma^j_{sk}$ (here $g_1^{ij}$ is the inverse matrix that represent
the contravariant metric induced by $g_{1\,ij}$), and $\Gamma^j_{sk}$ are the
usual Christoffel symbols of $g_{1\,ij}$.

The operator $A_2$ has the general structure
\begin{equation}
  A_2=\ddx{}\left(g^{ij}_2\ddx{}+c_{k}^{ij}u_{x}^{k}\right)\ddx{},  \label{casimir}
\end{equation}
where the inverse $g_{2\,ij}$ of the leading term transforms as a covariant
pseudo-Riemannian metric. From now on we drop the subscript $2$ for the metric
of $A_2$. It was proved in \cite{fpv} that, if we set
$c_{ijk}=g_{iq}g_{jp}c_{k}^{pq}$, then
\begin{displaymath}
  c_{ijk}=\frac{1}{3}(g_{ik,j}-g_{ij,k})
\end{displaymath}
and the metric fulfills the following identity:
\begin{equation}
  g_{mk,n}+g_{kn,m}+g_{mn,k}=0.
  \label{Killing}
\end{equation}
This means that the metric is a Monge metric \cite{fpv}. In particular, its
coefficients are quadratic in the variables $u^i$.
It is easy to input the two operators in \cde. Let us start by $A_1$: we may
define its entries one by one as follows
\begin{verbatim}
operator a1;

for all psi let a1(1,1,psi) = - (3/2)*td(psi,x);
for all psi let a1(1,2,psi) = (1/2)*td(a*psi,x);
...
\end{verbatim}
We could also use one specialized Reduce package for the computation of the
Christoffel symbols, like \texttt{RedTen} or \texttt{GRG}. Assuming that the
operators \texttt{gamma\_hi(i,j,k)} have been defined equal to $\Gamma^{ij}_k$
and computed in the system using the inverse matrix $g_{ij}$ of the leading
coefficient contravariant metric\footnote{Indeed in the example file
  \texttt{wdvv\_biham1.red} there are procedures for computing all those
  quantities.}
\begin{displaymath}
  g^{ij} =
  \begin{pmatrix}
    -\frac{3}{2} & \frac{1}{2}a & b
    \\
    \frac{1}{2}a & b & \frac{3}{2}c
    \\
    b & \frac{3}{2}c & 2(b^2-ac)
  \end{pmatrix}
\end{displaymath}
then, provided we defined a list \texttt{dep\_var} of the dependent variables,
we could set
\begin{verbatim}
operator gamma_hi_con;
for all i,j let gamma_hi_con(i,j) =
(
 for k:=1:3 sum gamma_hi(i,j,k)*mkid(part(dep_var,k),!_x)
)$
\end{verbatim}
and
\begin{verbatim}
operator a1$
for all i,j,psi let a1(i,j,psi) =
gu1(i,j)*td(psi,x)+(for k:=1:3 sum gamma_hi_con(i,j)*psi
)$
\end{verbatim}

The third order operator can be reconstructed as follows.
Observe that the leading contravariant metric is
\begin{displaymath}
  g^{ij}=
  \begin{pmatrix}
    0 & 0 & 1
    \\
    0 & 1 & -a
    \\
    1 & -a & 2b+a^2
  \end{pmatrix}
\end{displaymath}
Introduce the above matrix in \REDUCE as \texttt{gu3}. Then set
\begin{verbatim}
gu3:=gl3**(-1)$
\end{verbatim}
and define $c_{ijk}$ as
\begin{verbatim}
operator c_lo$
for i:=1:3 do
 for j:=1:3 do
  for k:=1:3 do
  <<
   c_lo(i,j,k):=
    (1/3)*(df(gl3(k,i),part(dep_var,j)) - df(gl3(j,i),part(dep_var,k)))$
  >>$
\end{verbatim}
Then define $c^{ij}_k$
\begin{verbatim}
templist:={}$
operator c_hi$
for i:=1:ncomp do
 for j:=1:ncomp do
  for k:=1:ncomp do
   c_hi(i,j,k):=
    <<
     templist:=
      for m:=1:ncomp join
       for n:=1:ncomp collect
        gu3(n,i)*gu3(m,j)*c_lo(m,n,k)$
     templist:=part(templist,0):=plus
    >>$
\end{verbatim}
Introduce the contracted operator
\begin{verbatim}
operator c_hi_con$
for i:=1:ncomp do
 for j:=1:ncomp do
  c_hi_con(i,j):=
   <<
    templist:=for k:=1:ncomp collect
     c_hi(i,j,k)*mkid(part(dep_var,k),!_x)$
    templist:=part(templist,0):=plus
   >>$
\end{verbatim}
Finally, define the operator $A_2$
\begin{verbatim}
operator aa2$
for all i,j,psi let aa2(i,j,psi) =
td(
gu3(i,j)*td(psi,x,2)+c_hi_con(i,j)*td(psi,x)
,x)$
\end{verbatim}
Now, we can test the Hamiltonian property of $A_1$, $A_2$ and their
compatibility:
\begin{verbatim}
conv_cdiff2genfun(aa1,sym1)$
conv_cdiff2genfun(aa2,sym2)$

conv_genfun2biv(sym1,biv1)$
conv_genfun2biv(sym2,biv2)$

schouten_bracket(biv1,biv1,sb11);
schouten_bracket(biv1,biv2,sb12);
schouten_bracket(biv2,biv2,sb22);
\end{verbatim}
Needless to say, the result of the last three command is a list of zeroes.

We observe that the same software can be used to prove the bi-Hamiltonianity of
a $6$-component WDVV system \cite{pv}.

\subsection{Schouten bracket of multidimensional operators}
\label{sec:mult-oper}

The formulae~\eqref{eq:11},~\eqref{eq:14} hold also in the case of
multidimensional operators, \emph{ie} operators with total derivatives in more
than one independent variables. Here we give one Hamiltonian operator $H$ and we
give two more variational bivectors $P_1$, $P_2$; all operators are of
Dubrovin--Novikov type (homogeneous). We check the compatibility
by computing $[H,P_1]$ and $[H,P_2]$. Such computations are standard for the
problem of computing the Hamiltonian cohomology of $H$.

This example has been provided by M. Casati. The file of the computation is
\texttt{dn2d\_sb1.red}. The dependent variables are $p^1$, $p^2$.

Let us set
\begin{gather}
  \label{eq:19}
  H=
  \begin{pmatrix}
    D_x & 0 \\ 0 & D_y
  \end{pmatrix}
  \\
  P_1 =\left(
  \begin{matrix}\displaystyle
    2 \pd{g}{p^1} p^2_y D_x +
    \pd{g}{p^1} p^2_{xy}  + \pd{g}{p^1\partial p^2} p^2_x p^2_y  +
    \pd{g}{^2p^1} p^1_x p^2_y
    \\
    \displaystyle
   -f D^2_x
  + g D_y^2 +
  \pd{g}{p^2} p^2_y D_y -
  (\pd{f}{p^1} p^1_x+2 \pd{f}{p^2} p^2_x) D_x
    - \pd{f}{^2p^2} p^2_x p^2_x  - \pd{f}{p^1\partial p^2} p^1_x p^2_x 
    - \pd{f}{p^2} p^2_2x ;
  \end{matrix}\right.
  \\
  \left.\begin{matrix}
    \displaystyle
    f D_x^2 - g D_y^2
  + \pd{f}{p^1} p^1_x D_x -
  \Big(\pd{g}{p^2} p^2_y + 2 \pd{g}{p^1} p^1_y\Big) D_y -
  \pd{g}{^2p^1} p^1_y p^1_y  - \pd{g}{p^1\partial p^2} p^1_y p^2_y
  - \pd{g}{p^1} p^1_{2y} ;
  \\
    \displaystyle
    2 \pd{f}{p^2} p^1_x D_y
  + \pd{f}{p^2} p^1_xy  + \pd{f}{p^1\partial p^2} p^1_x p^1_y 
    + \pd{f}{^2p^2} p^1_x p^2_y ;
  \end{matrix}\right)
\end{gather}
and let $P_2 = P_1^T$. This is implemented as follows:
\begin{verbatim}
mk_cdiffop(aa2,1,{2},2)$
for all psi let aa2(1,1,psi) = 2*df(g,p1)*p2_y*td(psi,x) +
  df(g,p1)*p2_xy*psi + df(g,p1,p2)*p2_x*p2_y*psi + df(g,p1,2)*p1_x*p2_y*psi;

for all psi let aa2(1,2,psi) = f*td(psi,x,2) - g*td(psi,y,2)
  + df(f,p1)*p1_x*td(psi,x) -
  (df(g,p2)*p2_y + 2*df(g,p1)*p1_y)*td(psi,y) -
  df(g,p1,2)*p1_y*p1_y*psi - df(g,p1,p2)*p1_y*p2_y*psi - df(g,p1)*p1_2y*psi;

for all psi let aa2(2,1,psi) = -f*td(psi,x,2)
  + g*td(psi,y,2) +
  df(g,p2)*p2_y*td(psi,y) -
  (df(f,p1)*p1_x+2*df(f,p2)*p2_x)*td(psi,x)
    - df(f,p2,2)*p2_x*p2_x*psi - df(f,p1,p2)*p1_x*p2_x*psi
      - df(f,p2)*p2_2x*psi;

for all psi let aa2(2,2,psi) = 2*df(f,p2)*p1_x*td(psi,y)
  + df(f,p2)*p1_xy*psi + df(f,p1,p2)*p1_x*p1_y*psi
    + df(f,p2,2)*p1_x*p2_y*psi;

mk_cdiffop(aa3,1,{2},2)$
for all psi let aa3(1,1,psi) = aa2(1,1,psi);
for all psi let aa3(1,2,psi) = aa2(2,1,psi);
for all psi let aa3(2,1,psi) = aa2(1,2,psi);
for all psi let aa3(2,2,psi) = aa2(2,2,psi);
\end{verbatim}
Let us check the skew-adjointness of the above bivectors:
\begin{verbatim}
conv_cdiff2superfun(aa1,sym1)$
conv_cdiff2superfun(aa2,sym2)$
conv_cdiff2superfun(aa3,sym3)$

adjoint_cdiffop(aa1,aa1_star);
adjoint_cdiffop(aa2,aa2_star);
adjoint_cdiffop(aa3,aa3_star);

for i:=1:2 do write sym1(i) + aa1_star_sf(i);
for i:=1:2 do write sym2(i) + aa2_star_sf(i);
for i:=1:2 do write sym3(i) + aa3_star_sf(i);
\end{verbatim}
Of course the last three commands produce two zeros each.

Let us compute Schouten brackets.
\begin{verbatim}
conv_cdiff2superfun(aa1,sym1)$
conv_cdiff2superfun(aa2,sym2)$
conv_cdiff2superfun(aa3,sym3)$

conv_genfun2biv(sym1,biv1)$
conv_genfun2biv(sym2,biv2)$
conv_genfun2biv(sym3,biv3)$

schouten_bracket(biv1,biv1,sb11);

schouten_bracket(biv1,biv2,sb12);

schouten_bracket(biv1,biv3,sb13);
\end{verbatim}
\texttt{sb11(1)} is trivially a list of zeros, while \texttt{sb12(1)} is
nonzero and \texttt{sb13(1)} is again zero.

\medskip

More formulae are currently being implemented in the system, like symplecticity
and Nijenhuis condition for recursion operators \cite{KKV2}. Interested readers
are warmly invited to contact R. Vitolo for questions/feature requests.


\section{Non-local operators}
\label{sec:non-local-hamilt}

In this section we will show an experimental way to find nonlocal
operators. The word `experimental' comes from the lack of a comprehensive
mathematical theory of nonlocal operators; in particular, it is still missing a
theoretical framework for Schouten brackets of nonlocal opeartors in the odd
variable language.

In any case we will achieve the results by means of a covering of the cotangent
covering.  Indeed, it can be proved that there is a $1-1$ correspondence
between (higher) symmetries of the initial equation and conservation laws on
the cotangent covering. Such conservation laws provide new potential variables,
hence a covering (see \cite{Many} for theoretical details on coverings).

In Section~\ref{sec:plebanski-equation} we will also discuss a procedure for
finding conservation laws from their generating functions that is of
independent interest.

\subsection{Non-local Hamiltonian operators for the
  Korteweg--de Vries equation}
\label{sec:korteweg-de-vries-1}

Here we will compute some nonlocal Hamiltonian operators for the KdV
equation. The result of the computation (without the details below) has been
published in \cite{KKV}.

We have to solve equations of the type \texttt{ddx(ct)-ddt(cx)} as
in~\ref{sec:local-cons-laws}. The main difference is that we will attempt a
solution on the $\ell^*$-covering (see Subsection~\ref{sec:local-hamilt-oper}).
For this reason, first of all we have to determine covering variables with the
usual mechanism of introducing them through conservation laws, this time on the
$\ell^*$-covering.

As a first step, let us compute conservation laws on the $\ell^*$-covering
whose components are linear in the $p$'s.  This computation can be found in the
file \texttt{kdv\_nlcl1} and related results and debug files.

The conservation laws that we are looking for are in $1-1$ correspondence with
symmetries of the initial equation \cite{KKV}. We will look for conservatoin
laws which correspond to Galilean boost, $x$-translation, $t$-translation at
the same time.  In the case of 2 independent variables and 1 dependent
variable, one could prove that one component of such conservation laws can
always be written as \texttt{sym*p} as follows:
\begin{verbatim}
c1x:=(t*u_x+1)*p$ % degree 1
c2x:=u_x*p$ % degree 4
c3x:=(u*u_x+u_3x)*p$ % degree 6
\end{verbatim}
The second component must be found by solving an equation. To this aim we
produce the ansatz
\begin{verbatim}
c1t:=f1*p+f2*p_x+f3*p_2x$
c2t:=(for each el in linodd6 sum (c(ctel:=ctel+1)*el))$ % degree 6
c3t:=(for each el in linodd8 sum (c(ctel:=ctel+1)*el))$ % degree 8
\end{verbatim}
where we already introduced the sets \texttt{linodd6} and \texttt{linodd8} of
$6$-th and $8$-th degree monomials which are linear in odd variables (see the
source code). For the first conservation law solutions of the equation
\begin{verbatim}
equ 1:=td(c1t,x) - td(c1x,t);
\end{verbatim}
are found by hand due to the presence of `t' in the symmetry:
\begin{verbatim}
f3:=t*u_x+1$
f2:=-td(f3,x)$
f1:=u*f3+td(f3,x,2)$
\end{verbatim}
We also have the equations
\begin{verbatim}
equ 2:=td(c2t,x)-td(c2x,t);
equ 3:=td(c3t,x)-td(c3x,t);
\end{verbatim}
They are solved in the usual way (see the source code of the example and the
results file \texttt{kdv\_nlcl1\_res}).

Now, we solve the equation for shadows of nonlocal symmetries in a covering of
the $\ell^*$-covering (source file \texttt{kdv\_nlho1}). We can produce
such a covering by introducing three new nonlocal (potential) variables
\texttt{ra,rb,rc}. We are going to look for non-local Hamiltonian operators
depending linearly on one of these variables. To this aim we modify the odd
part of the equation to include the components of the above conservation laws
as the derivatives of the new non-local variables \texttt{r1}, \texttt{r2},
\texttt{r3}:
\begin{verbatim}
principal_odd:={p_t,r1_x,r1_t,r2_x,r2_t,r3_x,r3_t}$
de_odd:={u*p_x+p_3x,
p*(t*u_x + 1),
p*t*u*u_x + p*t*u_3x + p*u + p_2x*t*u_x + p_2x - p_x*t*u_2x,
p*u_x,
p*u*u_x + p*u_3x + p_2x*u_x - p_x*u_2x,
p*(u*u_x + u_3x),
p*u**2*u_x + 2*p*u*u_3x + 3*p*u_2x*u_x + p*u_5x + p_2x*u*u_x + p_2x*
u_3x - p_x*u*u_2x - p_x*u_4x - p_x*u_x**2}$
\end{verbatim}
The scale degree analysis of the local Hamiltonian operators of the KdV
equation leads to the formulation of the ansatz
\begin{verbatim}
phi:=(for each el in linodd sum (c(ctel:=ctel+1)*el))$
\end{verbatim}
where \texttt{linext} is the list of graded mononials which are linear in odd
variables and have degree $7$ (see the source file).
The equation for shadows of nonlocal symmetries in $\ell^*$-covering
\begin{verbatim}
equ 1:=td(phi,t)-u*td(phi,x)-u_x*phi-td(phi,x,3);
\end{verbatim}
is solved in the usual way, obtaining (in odd variables notation):
\begin{verbatim}
phi := (c(5)*(4*p*u*u_x + 3*p*u_3x + 18*p_2x*u_x + 12*p_3x*u
 + 9*p_5x + 4*p_x*u**2 + 12*p_x*u_2x - r2*u_x))/4$
\end{verbatim}
Higher non-local Hamiltonian operators could also be found
\cite{KKV}. The CRACK approach also holds for non-local computations.


\subsection{Non-local recursion operator for the
  Korteweg--de Vries equation}
\label{sec:korteweg-de-vries-2}

Following the ideas in \cite{KKV}, a differential operator that sends
symmetries into symmetries can be found as a shadow of symmetry on the
$\ell$-covering of the KdV equation, with the further condition that the
shadows must be linear in the covering $q$-variables. The tangent covering of
the KdV equation is
\begin{displaymath}
  \left\{\begin{array}{l}
    u_t=u_{xxx}+uu_x\\
    q_t=u_xq + uq_x + q_{xxx}
  \end{array}\right.
\end{displaymath}
and we have to solve the equation $\bar\ell_{KdV}(\mathtt{phi})=0$, where
$\bar\ell_{KdV}$ means that the linearization of the KdV equation is lifted
over the tangent covering.

The file containing this example is \texttt{kdv\_ro1.red}. The example closely
follows the computational scheme presented in \cite{KKV-SPT-2011}.

Usually, recursion operators are non-local: operators of the
form $D_x^{-1}$ appear in their expression. Geometrically we interpret this
kind of operator as follows. We introduce a conservation law on the cotangent
covering of the form
\begin{displaymath}
  \omega = rt\,dx + rx\, dt
\end{displaymath}
where $rt = uq+q_{xx}$ and $rx = q$. It has the remarkable feature of being
linear with respect to $q$-variables. A non-local variable $r$ can be
introduced as a potential of $\omega$, as $r_x=rx$, $r_t=rt$. A computation
of shadows of symmetries on the system of PDEs
\begin{displaymath}
  \left\{\begin{array}{l}
    u_t=u_{xxx}+uu_x\\
    q_t=u_xq + uq_x + q_{xxx}\\
    r_t = uq+q_{xx}\\
    r_x = q
  \end{array}\right.
\end{displaymath}
yields, analogously to the previous computations,
\begin{verbatim}
  2*c(5)*q*u + 3*c(5)*q_2x + c(5)*r*u_x + c(2)*q.
\end{verbatim}
The operator $q$ stands for the identity operator, which is (and must be!)
always a solution; the other solution corresponds to the Lenard--Magri operator
\begin{displaymath}
  3D_{xx} + 2u + u_xD_x^{-1}.
\end{displaymath}



\subsection{Non-local Hamiltonian-recursion operators for
  Plebanski equation}
\label{sec:plebanski-equation}

The Plebanski (or second Heavenly) equation
\begin{equation}
  \label{eq:41}
  F=u_{tt}u_{xx}-u_{tx}^2+u_{xz}+u_{ty}=0
\end{equation}
is Lagrangian, hence it admits a trivial local Hamiltonian operator which is
just the Noether map. Nonlocal Hamiltonian and recursion operators have been
computed in an evolutionary presentation of the equation in
\cite{NeyziNutkuSheftel:JPA:2005}. We can recompute such operators in the above
Lagrangian presentation as follows.

First of all, we remark that in a Lagrangian presentation symmetries and
cosymmetries coincide, since the equation is self-adjoint. This means that
the concept of Hamiltonian, recursion, symplectic operators coincide.
So, instead of trying to find a variety of operators we may focus on just one
type of search.

Then, by introducing a suitable nonlocal variable on the cotangent
covering. Namely, we compute a linear conservation law (with respect to $p$'s)
on the cotangent covering which corresponds with the $u$-translation symmetry
(see \cite{KKV-SPT-2011} for a theoretical description).  We can guess that the
generating function of the conservation law is $\psi=(0,1)$. This comes from
the generating function $\phi=1$ of the $u$-translation symmetry by the
correspondence that is described in \cite{KKV-SPT-2011}. Then we should find
the corresponding conservation law by solving a system of PDEs. Luckily
it is not difficult to realize that the above equation can be written in
explicit conservative form as
\begin{multline*}
    p_{xz}+p_{ty}+u_{tt}p_{xx}+u_{xx}p_{tt}-2u_{tx}p_{tx} \\
    =D_x(p_z+u_{tt}p_x-u_{tx}p_t)+D_t(p_y+u_{xx}p_t-u_{tx}p_x)=0,
\end{multline*}
thus the corresponding conservation law is
\begin{equation}
  \label{eq:32}
  \upsilon(1)= (p_y+u_{xx}p_t-u_{tx}p_x)\,dx\wedge dy\wedge dz+
          (u_{tx}p_t-p_z-u_{tt}p_x)\,dt\wedge dy\wedge dz.
        \end{equation}
We can introduce a potential $r$ for the above $2$-component conservation
law. Namely, we can assume that
\begin{equation}\label{eq:101}
  r_x = p_y+u_{xx}p_t-u_{tx}p_x,\quad r_t = u_{tx}p_t-p_z-u_{tt}p_x.
\end{equation}
This is a new nonlocal variable for the (co)tangent covering of the Plebanski
equation. We can load the Plebanski equation together with its nonlocal
variable $r$ as follows:
\begin{verbatim}
indep_var:={t,x,y,z}$
dep_var:={u}$
odd_var:={p,r}$
deg_indep_var:={-1,-1,-4,-4}$
deg_dep_var:={1}$
deg_odd_var:={1,4}$
total_order:=6$
principal_der:={u_xz}$
de:={-u_ty+u_tx**2-u_2t*u_2x}$
% rhs of the equations that define the nonlocal variable
rt:= - p_z - u_2t*p_x + u_tx*p_t$
rx:= p_y + u_2x*p_t - u_tx*p_x$
% We add conservation laws as new nonlocal odd variables;
principal_odd:={p_xz,r_x,r_t}$
%
de_odd:={-p_ty+2*u_tx*p_tx-u_2x*p_2t-u_2t*p_2x,rx,rt}$
\end{verbatim}
We can easily verify that the integrability condition for the new nonlocal
variable holds:
\begin{verbatim}
td(r,t,x) - td(r,x,t);
\end{verbatim}
the result is $0$.

This allows us to introduce a new nonlocal \emph{odd} variable $r$ on the
cotangent covering such that $r_x=ct$, $r_t=cx$. We obtain an Abelian covering
of the cotangent covering:
\begin{displaymath}
  \left\{
    \begin{array}{l}
      r_x=ct,\\ r_t=cx,\\ \ell_F^*(p)=0, \\ F=0.
    \end{array}
  \right.
\end{displaymath}

A nonlocal Hamiltonian operator will be a shadow of symmetry of the above
system with respect to the initial equation $F=0$ with the property of being
linear with respect to all ($p$'s and $r$'s) odd variables. With the above
nonlocal variable we find a nonlocal Hamiltonian operator which, after changing
coordinates to the evolutionary presentation of
\cite{NeyziNutkuSheftel:JPA:2005}, coincides with one of the nonlocal
Hamiltonian operators presented in that paper\footnote{We observe that in
  \cite{NeyziNutkuSheftel:JPA:2005} also the trivial Hamiltonian operator is
  recovered in the evolutionary presentation; of course it has an apparently
  nontrivial expression.}. Here follows the code.
\begin{verbatim}
indep_var:={t,x,y,z}$
dep_var:={u}$
odd_var:={p,r}$
deg_indep_var:={-1,-1,-4,-4}$
deg_dep_var:={1}$
deg_odd_var:={1,4}$
total_order:=6$
principal_der:={u_xz}$
de:={-u_ty+u_tx**2-u_2t*u_2x}$
% rhs of the equations that define the nonlocal variable
rt:=p_2t*u_x - p_2tx*u - 2*p_tx*u_t + p_z$
rx:=- p_2x*u_t - p_t2x*u - p_y$
% We add conservation laws as new nonlocal odd variables;
principal_odd:={p_xz,r_x,r_t}$
%
de_odd:={-p_ty+2*u_tx*p_tx-u_2x*p_2t-u_2t*p_2x,rx,rt}$
\end{verbatim}
We look for Hamiltonian operators which depend on $r$ (which has scale degree
$4$); we produce the following ansatz for \texttt{phi}:
\begin{verbatim}
linodd:=mkalllinodd_e(gradmon,l_grad_odd,1,4)$
phi:=(for each el in linodd sum (c(ctel:=ctel+1)*el))$
\end{verbatim}
then we solve the equation of shadows of symmetries:
\begin{verbatim}
equ 1:=td(phi,x,z)+td(phi,t,y)-2*u_tx*td(phi,t,x)
+u_2x*td(phi,t,2)+u_2t*td(phi,x,2)$
\end{verbatim}
The solution is
\begin{verbatim}
phi := c(28)*r + c(1)*p
\end{verbatim}
hence we obtain the Noether map (the identity operator $p$) and the new
nonlocal operator $r$. It can be proved that changing coordinates to the
evolutionary presentation yields the local operator (which has a much more
complex expression than the identity operator) and one of the nonlocal
operators of \cite{NeyziNutkuSheftel:JPA:2005}. More details on this
computation can be found in \cite{KKV-SPT-2011}.


\section{Appendix: old versions of \cde}

A short version history is provided here.

\paragraph{\cde 1.0} This version was published in October 2014. It was
programmed in \reduce's \textbf{algebraic mode}, so its capabilities were
limited, and its speed was severely affected by the systematic use of the
package \texttt{assist} for manipulating algebraic lists. Its features were:
\begin{enumerate}
\item \cde 1.0 is able to do standard computations in integrable systems like
  determining systems for generalized symmetries and conservation laws.
\item \cde 1.0 is able to compute linear overdetermined systems of partial
  differential equations whose solutions are Hamiltonian operators.
\item \cde is able to compute Schouten brackets between bivectors. This can be
  used \emph{eg} to check Hamiltonianity of an operator, or the compatibility
  of two operators.
\end{enumerate}
\cde 1.0 has never ben included in the official \reduce distribution, and it is
still available at \cite{gdeq}.

\begin{thebibliography}{99}

\bibitem{red} Obtaining \reduce: \url{http://reduce-algebra.sourceforge.net/}.
\bibitem{gdeq} Geometry of Differential Equations web site:
  \url{http://gdeq.org}.
\bibitem{noteppp} \texttt{notepad++}:
  \url{http://notepad-plus.sourceforge.net/}
\bibitem{ed} List of text editors:
  \url{http://en.wikipedia.org/wiki/List_of_text_editors}
\bibitem{emacswin} How to install \texttt{emacs} in Windows:
  \url{http://www.cmc.edu/math/alee/emacs/emacs.html}. See also
  \url{http://www.gnu.org/software/emacs/windows/ntemacs.html}
\bibitem{reducewin} How to install \reduce in Windows:
  \url{http://reduce-algebra.sourceforge.net/windows.html}
\bibitem{svec} \textsc{G.H.M. Roelofs}, The SUPER\_VECTORFIELD package for
  REDUCE. Version 1.0, Memorandum 1099, Dept. Appl. Math., University of
  Twente, 1992. Available at \url{http://gdeq.org}.
\bibitem{integ} \textsc{G.H.M. Roelofs}, The INTEGRATOR package for
  REDUCE. Version 1.0, Memorandum 1100, Dept. Appl. Math., University of
  Twente, 1992. Available at \url{http://gdeq.org}.
\bibitem{tools} \textsc{G.F. Post}, A manual for the package TOOLS 2.1,
  Memorandum 1331, Dept. Appl. Math., University of Twente, 1996. Available at
  \url{http://gdeq.org}.
\bibitem{redide} \reduce IDE for \texttt{emacs}:
  \url{http://centaur.maths.qmul.ac.uk/Emacs/REDUCE_IDE/}
\bibitem{Many} \textsc{A. V. Bocharov, V. N. Chetverikov, S. V.  Duzhin, N.  G.
    Khor{\cprime}kova, I. S.  Krasil{\cprime}shchik, A.  V.  Samokhin, Yu.\ N.
    Torkhov, A. M. Verbovetsky and A. M.  Vinogradov}: Symmetries and
  Conservation Laws for Differential Equations of Mathematical Physics, I.  S.
  Krasil{\cprime}shchik and A. M.  Vinogradov eds., Translations of Math.
  Monographs \textbf{182}, Amer.\ Math.\ Soc. (1999).
\bibitem{BH10} \textsc{D. Baldwin, W. Hereman}, \emph{A symbolic algorithm
    for computing recursion operators of nonlinear partial differential
    equations}, International Journal of Computer Mathematics, vol. 87 (5),
  pp. 1094-1119 (2010).
\bibitem{Dub} \textsc{B.A. Dubrovin}, \newblock Geometry of 2D topological
field theories, Lecture Notes in Math. 1620, Springer-Verlag (1996) 120--348.
\bibitem{DN} \textsc{B.A. Dubrovin and S.P. Novikov}, \newblock Hamiltonian
  formalism of one-dimensional systems of hydrodynamic type and the
  Bogolyubov-Whitham averaging method, Soviet Math. Dokl. \textbf{27} No. 3
  (1983) 665--669.
\bibitem{DN2} \textsc{B.A. Dubrovin and S.P. Novikov}, Poisson brackets of
  hydrodynamic type, Soviet Math. Dokl. {\bf 30} No. 3 (1984), 651--2654.
\bibitem{FN} \textsc{E.V. Ferapontov, C.A.P. Galvao, O. Mokhov, Y. Nutku},
  Bi-Hamiltonian structure of equations of associativity in 2-d
  topological field theory, Comm. Math. Phys. \textbf{186 }(1997) 649-669.
\bibitem{fpv} \textsc{E.V. Ferapontov, M.V. Pavlov, R.F. Vitolo},
\emph{Projective-geometric aspects of homogeneous third-order Hamiltonian
operators}, J. Geom.\ Phys.\ \textbf{85} (2014) 16-28, DOI:
10.1016/j.geomphys.2014.05.027.
\bibitem{fpv2} \textsc{E.V. Ferapontov, M.V. Pavlov, R.F. Vitolo},
\emph{Towards the classification of homogeneous third-order Hamiltonian
  operators}, \url{http://arxiv.org/abs/1508.02752}
\bibitem{getz} \emph{E. Getzler}, A Darboux theorem for Hamiltonian
operators in the formal calculus of variations, Duke J. Math. \textbf{111}
(2002), 535-560.
\bibitem{IVV}\textsc{S. Igonin, A. Verbovetsky, R. Vitolo:}
  \emph{Variational Multivectors and Brackets in the Geometry of Jet Spaces}, V
  Int. Conf. on on Symmetry in Nonlinear Mathematical Physics, Kyiv 2003; Part
  3 of Volume 50 of Proceedings of Institute of Mathematics of NAS of Ukraine,
  Editors A.G.  Nikitin, V.M. Boyko, R.O. Popovych and I.A. Yehorchenko (2004),
  1335--1342; \url{http://www.imath.kiev.ua/~snmp2003/Proceedings/vitolo.pdf}.
\bibitem{KKV} \textsc{P.H.M. Kersten, I.S. Krasil'shchik, A.M. Verbovetsky,}
  \emph{Hamiltonian operators and $\ell^*$-covering}, Journal of Geometry and
  Physics \textbf{50} (2004), 273--302.
\bibitem{KKV2} \textsc{P.H.M. Kersten, I.S. Krasil'shchik, A.M. Verbovetsky,}
  \emph{A geometric study of the dispersionless Boussinesq equation}, Acta
  Appl.\ Math. \textbf{90} (2006), 143--178.
\bibitem{KerstenKrasilshchikVerbovetskyVitolo:HSGP} \textsc{P.~Kersten,
  I.~Krasil{\cprime}shchik, A.~Verbovetsky, and R.~Vitolo}, \emph{Hamiltonian
    structures for general {PDE}s}, Differential equations: Geometry,
  Symmetries and Integrability. The Abel Symposium 2008 (B.~Kruglikov,
  V.~V. Lychagin, and E.~Straume, eds.), Springer-Verlag, 2009, pp.~187--198,
  \eprint{0812.4895}.
\bibitem{KrVe-JGP-2011} \textsc{I.~Krasil{\cprime}shchik and A.~Verbovetsky},
  \emph{Geometry of jet spaces and integrable systems}, J.\ Geom.\
  Phys. (2011) doi:10.1016/j.geomphys.2010.10.012, \url{arXiv:1002.0077}.
\bibitem{KKV-SPT-2011} \textsc{I.~Krasil{\cprime}shchik, A.~Verbovetsky,
    R. Vitolo},  \emph{A unified approach to computation of integrable
    structures}, Acta Appl.\ Math.\ (2012).
\bibitem{KVV-book} \textsc{I.~Krasil{\cprime}shchik, A.~Verbovetsky,
    R. Vitolo},  \emph{The symbolic computation of integrability structures for
    partial differential equations}, book, to appear in the Springer series
``Texts and monographs in symbolic computations'' (2017).
\bibitem{Kupershmidt:KP} \textsc{B. Kuperschmidt}:
  \emph{Geometric Hamiltonian forms for the
    Kadomtsev--Petviashvili and Zabolotskaya--Khokhlov equations}, in Geometry
  in Partial Differential Equations, A. Prastaro, Th.M. Rassias eds., World
  Scientific (1994), 155--172.
\bibitem{Mar} \textsc{M. Marvan}, \emph{Sufficient set of integrability
    conditions of an orthonomic system}.  Foundations of Computational
    Mathematics \textbf{9} (2009), 651--674.
\bibitem{NeyziNutkuSheftel:JPA:2005} \textsc{F. Neyzi, Y. Nutku, and
      M.B. Sheftel}, \emph{Multi-Hamiltonian structure of Plebanski's second
      heavenly equation} J. Phys.\ A: Math.\ Gen.\ \textbf{38} (2005),
    8473. \eprint{nlin/0505030v2}.
  \bibitem{inside} \textsc{A.C. Norman, R. Vitolo}, \emph{Inside Reduce}, part
    of the official \reduce documentation included in the source code, see
    below.
\bibitem{nucci1} \textsc{M.C. Nucci}, \emph{Interactive REDUCE
      programs for calculating classical, non-classical, and approximate
      symmetries of differential equations}, in Computational and Applied
    Mathematics II. Differential Equations, W.F. Ames, and P.J. Van der Houwen,
    Eds., Elsevier, Amsterdam (1992) pp. 345--350.
\bibitem{nucci2} \textsc{M.C. Nucci}, \emph{Interactive REDUCE programs for
    calculating Lie point, non-classical, Lie-Bcklund, and approximate
    symmetries of differential equations: manual and floppy disk}, in
CRC Handbook of Lie Group Analysis of Differential Equations. Vol. 3
N.H. Ibragimov, Ed., CRC Press, Boca Raton (1996) pp. 415--481.
\bibitem{relie} \textsc{F. Oliveri}, \textsc{ReLie}, \reduce software and user
  guide, \url{http://mat521.unime.it/oliveri/}.
\bibitem{Olv} \textsc{P. Olver}, Applications of Lie Groups to Partial
  Differential Equations, 2nd ed, GTM Springer, 1992.
\bibitem{pv} \textsc{M.V. Pavlov, R.F. Vitolo}: \emph{On the bi-Hamiltonian
    geometry of the WDVV equations}, \texttt{http://arxiv.org/abs/1409.7647}
\bibitem{sv} \textsc{G. Saccomandi, R. Vitolo}: \emph{On the Mathematical
    and Geometrical Structure of the Determining Equations for Shear Waves in
    Nonlinear Isotropic Incompressible Elastodynamics}, J. Math.\ Phys.\
  \textbf{55} (2014), 081502.
\bibitem{reduce} \reduce official website:
  \url{http://reduce-algebra.sourceforge.net/}.
\bibitem{wolfcl} \textsc{T. Wolf}, \emph{A comparison of four approaches to the
    calculation of conservation laws}, Euro.\ Jnl of Applied Mathematics 13
  part 2 (2002) 129-152.
\bibitem{wolfsy} \textsc{T. Wolf}, \emph{APPLYSYM - a package for the
    application of Lie-symmetries}, software distributed together with the
  computer algebra system REDUCE, (1995).
\bibitem{wbde} \textsc{T. Wolf, A. Brand}, \emph{Investigating DEs with CRACK
    and Related Programs}, SIGSAM Bulletin, Special Issue, (June 1995), p 1-8.
\bibitem{wolfsy0} \textsc{T. Wolf}, \emph{An efficiency improved program LIEPDE
    for determining Lie-symmetries of PDEs}, Proc.of Modern Group Analysis:
  advanced analytical and computational methods in mathematical physics,
  Catania, Italy Oct.1992, Kluwer Acad.Publ. (1993) 377-385.
\bibitem{crack} \textsc{T. Wolf, A. Brand}: CRACK, user guide, examples and
    documentation \url{http://lie.math.brocku.ca/Crack_demo.html}. For
    applications, see also the publications of T. Wolf.
\end{thebibliography}

\end{document}
